{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybbA7gxygDHm",
        "outputId": "f36caf38-857c-4675-bfec-156044db110d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q wandb torch torchvision pandas numpy matplotlib seaborn scikit-learn mlflow pytorch_lightning pytorch_forecasting\n",
        "\n",
        "# Set up Kaggle API\n",
        "!pip install -q kaggle pytorch_forecasting pytorch_lightning dagshub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8n9w-H2gFpK",
        "outputId": "b5dbb3db-fa4c-4d7d-ba73-255f5f3fa0a7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m260.9/260.9 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m821.1/821.1 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m733.8/733.8 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m261.0/261.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload your kaggle.json to Colab and run:\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/ColabNotebooks/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "cpCE_wwigPl6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "!kaggle competitions download -c walmart-recruiting-store-sales-forecasting\n",
        "!unzip -q walmart-recruiting-store-sales-forecasting.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqPcDgRCgQPC",
        "outputId": "eca31d89-d028-4049-c289-f1526b73310c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading walmart-recruiting-store-sales-forecasting.zip to /content\n",
            "\r  0% 0.00/2.70M [00:00<?, ?B/s]\n",
            "\r100% 2.70M/2.70M [00:00<00:00, 669MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q train.csv.zip\n",
        "!unzip -q stores.csv.zip\n",
        "!unzip -q test.csv.zip\n",
        "!unzip -q features.csv.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naG0PTJsgSz_",
        "outputId": "8222053b-3521-4286-e0f8-5af98cc3311c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open stores.csv.zip, stores.csv.zip.zip or stores.csv.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "# Prophet Model Experiment Notebook\n",
        "\n",
        "áƒ”áƒ¡ áƒœáƒáƒ£áƒ—áƒ‘áƒ£áƒ¥áƒ˜ áƒ’áƒáƒœáƒ™áƒ£áƒ—áƒ•áƒœáƒ˜áƒšáƒ˜áƒ Walmart Store Sales Forecasting Kaggle-áƒ˜áƒ¡ áƒ™áƒáƒœáƒ™áƒ£áƒ áƒ¡áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡ Prophet áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ”áƒ¥áƒ¡áƒáƒ”áƒ áƒ˜áƒ›áƒ”áƒœáƒ¢áƒ”áƒ‘áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡.\n",
        "áƒ˜áƒ’áƒ˜ áƒ›áƒáƒ˜áƒªáƒáƒ•áƒ¡ áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ—áƒ áƒ©áƒáƒ¢áƒ•áƒ˜áƒ áƒ—áƒ•áƒáƒ¡, áƒ¬áƒ˜áƒœáƒáƒ¡áƒ¬áƒáƒ  áƒ“áƒáƒ›áƒ£áƒ¨áƒáƒ•áƒ”áƒ‘áƒáƒ¡, Prophet áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ•áƒáƒ áƒ¯áƒ˜áƒ¨áƒ¡, áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒáƒ¡\n",
        "áƒ“áƒ MLflow-áƒ–áƒ” áƒ”áƒ¥áƒ¡áƒáƒ”áƒ áƒ˜áƒ›áƒ”áƒœáƒ¢áƒ”áƒ‘áƒ˜áƒ¡ áƒšáƒáƒ’áƒ˜áƒ áƒ”áƒ‘áƒáƒ¡.\n",
        "\"\"\"\n",
        "import mlflow\n",
        "# --- 1. áƒ‘áƒ˜áƒ‘áƒšáƒ˜áƒáƒ—áƒ”áƒ™áƒ”áƒ‘áƒ˜áƒ¡ áƒ˜áƒ›áƒáƒáƒ áƒ¢áƒ˜ ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from prophet import Prophet\n",
        "from prophet.diagnostics import cross_validation, performance_metrics\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import mlflow\n",
        "import mlflow.pyfunc\n",
        "import warnings\n",
        "import dagshub\n",
        "import joblib # áƒ“áƒáƒ•áƒáƒ›áƒáƒ¢áƒ” joblib áƒ‘áƒ˜áƒ‘áƒšáƒ˜áƒáƒ—áƒ”áƒ™áƒ áƒ¡áƒ”áƒ áƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"áƒ¡áƒáƒ­áƒ˜áƒ áƒ áƒ‘áƒ˜áƒ‘áƒšáƒ˜áƒáƒ—áƒ”áƒ™áƒ”áƒ‘áƒ˜ áƒ¬áƒáƒ áƒ›áƒáƒ¢áƒ”áƒ‘áƒ˜áƒ— áƒ˜áƒ›áƒáƒáƒ áƒ¢áƒ˜áƒ áƒ”áƒ‘áƒ£áƒšáƒ˜áƒ.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "áƒ¡áƒáƒ­áƒ˜áƒ áƒ áƒ‘áƒ˜áƒ‘áƒšáƒ˜áƒáƒ—áƒ”áƒ™áƒ”áƒ‘áƒ˜ áƒ¬áƒáƒ áƒ›áƒáƒ¢áƒ”áƒ‘áƒ˜áƒ— áƒ˜áƒ›áƒáƒáƒ áƒ¢áƒ˜áƒ áƒ”áƒ‘áƒ£áƒšáƒ˜áƒ.\n"
          ]
        }
      ],
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Oc_i5mHef1u",
        "outputId": "074b7efa-7328-4976-cb4b-22762b4240a6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- 2. MLflow áƒ™áƒáƒœáƒ¤áƒ˜áƒ’áƒ£áƒ áƒáƒªáƒ˜áƒ ---\n",
        "# MLflow Tracking URI-áƒ˜áƒ¡ áƒ“áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ. áƒ—áƒ£ áƒ˜áƒ§áƒ”áƒœáƒ”áƒ‘áƒ— áƒšáƒáƒ™áƒáƒšáƒ£áƒ  MLflow áƒ¡áƒ”áƒ áƒ•áƒ”áƒ áƒ¡, áƒ¨áƒ”áƒªáƒ•áƒáƒšáƒ”áƒ— áƒ¨áƒ”áƒ¡áƒáƒ‘áƒáƒ›áƒ˜áƒ¡áƒáƒ“.\n",
        "# áƒ›áƒáƒ’áƒáƒšáƒ˜áƒ—áƒáƒ“: \"http://localhost:5000\"\n",
        "import dagshub\n",
        "dagshub.init(repo_owner='ekvirika', repo_name='WalmartRecruiting', mlflow=True)\n",
        "mlflow.autolog()\n",
        "\n",
        "\n",
        "print(f\"MLflow Tracking URI áƒ“áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ£áƒšáƒ˜áƒ: {mlflow.get_tracking_uri()}\")\n",
        "\n",
        "# áƒ”áƒ¥áƒ¡áƒáƒ”áƒ áƒ˜áƒ›áƒ”áƒœáƒ¢áƒ˜áƒ¡ áƒ¡áƒáƒ®áƒ”áƒšáƒ˜áƒ¡ áƒ“áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ\n",
        "experiment_name = \"Prophet_Training\"\n",
        "mlflow.set_experiment(experiment_name)\n",
        "print(f\"MLflow áƒ”áƒ¥áƒ¡áƒáƒ”áƒ áƒ˜áƒ›áƒ”áƒœáƒ¢áƒ˜ áƒ“áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ£áƒšáƒ˜áƒ: {experiment_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319,
          "referenced_widgets": [
            "9ca35ad8a798492186fa18149b612d57",
            "d88cd209fd6e473fb61429496d14899b"
          ]
        },
        "id": "pqqUq0f_iNO7",
        "outputId": "baff6f3c-b2f3-478e-c6a4-89348f93222b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                       \u001b[1mâ—â—â— AUTHORIZATION REQUIRED â—â—â—\u001b[0m                                        \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">â—â—â— AUTHORIZATION REQUIRED â—â—â—</span>                                        \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ca35ad8a798492186fa18149b612d57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Open the following link in your browser to authorize the client:\n",
            "https://dagshub.com/login/oauth/authorize?state=d96a3b54-4c07-4b5e-a688-57f7b864cfd2&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=b9a51f27d8eae2cc62f6856576ffbb7c85d32944f09a8ca568dd0665dcb044d1\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Accessing as ekvirika\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as ekvirika\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"ekvirika/WalmartRecruiting\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"ekvirika/WalmartRecruiting\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Repository ekvirika/WalmartRecruiting initialized!\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository ekvirika/WalmartRecruiting initialized!\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/07/07 20:19:09 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
            "2025/07/07 20:19:09 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
            "2025/07/07 20:19:09 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
            "2025/07/07 20:19:09 INFO mlflow.tracking.fluent: Experiment with name 'Prophet_Training' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLflow Tracking URI áƒ“áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ£áƒšáƒ˜áƒ: https://dagshub.com/ekvirika/WalmartRecruiting.mlflow\n",
            "MLflow áƒ”áƒ¥áƒ¡áƒáƒ”áƒ áƒ˜áƒ›áƒ”áƒœáƒ¢áƒ˜ áƒ“áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ£áƒšáƒ˜áƒ: Prophet_Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- 3. áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ—áƒ áƒ©áƒáƒ¢áƒ•áƒ˜áƒ áƒ—áƒ•áƒ ---\n",
        "# áƒ¨áƒ”áƒœáƒ˜áƒ¨áƒ•áƒœáƒ: áƒáƒ¥ áƒ£áƒœáƒ“áƒ áƒ›áƒ˜áƒ£áƒ—áƒ˜áƒ—áƒáƒ— áƒ—áƒ¥áƒ•áƒ”áƒœáƒ˜ áƒ áƒ”áƒáƒšáƒ£áƒ áƒ˜ áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ—áƒ áƒ¤áƒáƒ˜áƒšáƒ”áƒ‘áƒ˜áƒ¡ áƒ’áƒ–áƒ”áƒ‘áƒ˜.\n",
        "# áƒáƒ› áƒ›áƒáƒ’áƒáƒšáƒ˜áƒ—áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡ áƒ’áƒáƒ›áƒáƒ§áƒ”áƒœáƒ”áƒ‘áƒ£áƒšáƒ˜áƒ áƒ¤áƒšáƒ”áƒ˜áƒ¡áƒ°áƒáƒšáƒ“áƒ”áƒ áƒ”áƒ‘áƒ˜.\n",
        "try:\n",
        "    train_df = pd.read_csv(\"train.csv\")\n",
        "    test_df = pd.read_csv(\"test.csv\")\n",
        "    stores_df = pd.read_csv(\"stores.csv\")\n",
        "    features_df = pd.read_csv(\"features.csv\")\n",
        "except FileNotFoundError:\n",
        "    print(\"áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ: áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ—áƒ áƒ¤áƒáƒ˜áƒšáƒ”áƒ‘áƒ˜ áƒ•áƒ”áƒ  áƒ›áƒáƒ˜áƒ«áƒ”áƒ‘áƒœáƒ. áƒ’áƒ—áƒ®áƒáƒ•áƒ—, áƒ“áƒáƒ áƒ¬áƒ›áƒ£áƒœáƒ“áƒ˜áƒ—, áƒ áƒáƒ› 'train.csv', 'test.csv', 'stores.csv', 'features.csv' áƒáƒ áƒ¡áƒ”áƒ‘áƒáƒ‘áƒ¡.\")\n",
        "    print(\"áƒáƒ› áƒœáƒáƒ£áƒ—áƒ‘áƒ£áƒ¥áƒ˜áƒ¡ áƒ’áƒáƒ¡áƒáƒ¨áƒ•áƒ”áƒ‘áƒáƒ“ áƒ¡áƒáƒ­áƒ˜áƒ áƒáƒ áƒ”áƒ¡ áƒ¤áƒáƒ˜áƒšáƒ”áƒ‘áƒ˜ áƒáƒœ áƒ®áƒ”áƒšáƒáƒ•áƒœáƒ£áƒ áƒ˜ áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ”áƒ‘áƒ˜áƒ¡ áƒ¨áƒ”áƒ¥áƒ›áƒœáƒ.\")\n",
        "    exit() # áƒ’áƒáƒ©áƒ”áƒ áƒ”áƒ‘áƒ áƒ—áƒ£ áƒ¤áƒáƒ˜áƒšáƒ”áƒ‘áƒ˜ áƒ•áƒ”áƒ  áƒ›áƒáƒ˜áƒ«áƒ”áƒ‘áƒœáƒ\n",
        "\n",
        "# --- 4. áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ—áƒ áƒ¬áƒ˜áƒœáƒáƒ¡áƒ¬áƒáƒ áƒ˜ áƒ“áƒáƒ›áƒ£áƒ¨áƒáƒ•áƒ”áƒ‘áƒ (MLflow Run: Prophet_Cleaning) ---\n",
        "with mlflow.start_run(run_name=\"Prophet_Cleaning\") as cleaning_run:\n",
        "    print(\"áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ—áƒ áƒ¬áƒ˜áƒœáƒáƒ¡áƒ¬áƒáƒ áƒ˜ áƒ“áƒáƒ›áƒ£áƒ¨áƒáƒ•áƒ”áƒ‘áƒ áƒ˜áƒ¬áƒ§áƒ”áƒ‘áƒ...\")\n",
        "\n",
        "    # áƒ—áƒáƒ áƒ˜áƒ¦áƒ”áƒ‘áƒ˜áƒ¡ áƒ¤áƒáƒ áƒ›áƒáƒ¢áƒ˜áƒ¡ áƒ¨áƒ”áƒªáƒ•áƒšáƒ\n",
        "    train_df['Date'] = pd.to_datetime(train_df['Date'])\n",
        "    test_df['Date'] = pd.to_datetime(test_df['Date'])\n",
        "    features_df['Date'] = pd.to_datetime(features_df['Date'])\n",
        "\n",
        "    # Extract date-related features\n",
        "    for df in [train_df, test_df]:\n",
        "        df['Year'] = df['Date'].dt.year\n",
        "        df['Month'] = df['Date'].dt.month\n",
        "        df['Week'] = df['Date'].dt.isocalendar().week\n",
        "        df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
        "\n",
        "    # Holiday flags for known holidays\n",
        "    holiday_dates = {\n",
        "        \"Super Bowl\": [\"2010-02-12\", \"2011-02-11\", \"2012-02-10\", \"2013-02-08\"],\n",
        "        \"Labor Day\": [\"2010-09-10\", \"2011-09-09\", \"2012-09-07\", \"2013-09-06\"],\n",
        "        \"Thanksgiving\": [\"2010-11-26\", \"2011-11-25\", \"2012-11-23\", \"2013-11-29\"],\n",
        "        \"Christmas\": [\"2010-12-31\", \"2011-12-30\", \"2012-12-28\", \"2013-12-27\"]\n",
        "    }\n",
        "\n",
        "\n",
        "    for holiday, dates in holiday_dates.items():\n",
        "        for df in [train_df, test_df]:\n",
        "            df[holiday] = df['Date'].isin(pd.to_datetime(dates)).astype(int)\n",
        "\n",
        "\n",
        "    # áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ—áƒ áƒ’áƒáƒ”áƒ áƒ—áƒ˜áƒáƒœáƒ”áƒ‘áƒ\n",
        "    # áƒ’áƒáƒ”áƒ áƒ—áƒ˜áƒáƒœáƒ”áƒ‘áƒ features_df-áƒ—áƒáƒœ\n",
        "    train_df = pd.merge(train_df, features_df, on=['Store', 'Date', 'IsHoliday'], how='left', suffixes=('_train', '_features'))\n",
        "    test_df = pd.merge(test_df, features_df, on=['Store', 'Date', 'IsHoliday'], how='left', suffixes=('_test', '_features'))\n",
        "\n",
        "    # áƒ’áƒáƒ”áƒ áƒ—áƒ˜áƒáƒœáƒ”áƒ‘áƒ stores_df-áƒ—áƒáƒœ\n",
        "    train_df = pd.merge(train_df, stores_df, on='Store', how='left')\n",
        "    test_df = pd.merge(test_df, stores_df, on='Store', how='left')\n",
        "\n",
        "    # Weekly_Sales-áƒ˜áƒ¡ áƒ£áƒáƒ áƒ§áƒáƒ¤áƒ˜áƒ—áƒ˜ áƒ›áƒœáƒ˜áƒ¨áƒ•áƒœáƒ”áƒšáƒáƒ‘áƒ”áƒ‘áƒ˜áƒ¡ áƒ“áƒáƒ›áƒ£áƒ¨áƒáƒ•áƒ”áƒ‘áƒ (áƒ—áƒ£ áƒáƒ áƒ¡áƒ”áƒ‘áƒáƒ‘áƒ¡)\n",
        "    # Prophet áƒáƒ  áƒ£áƒ­áƒ”áƒ áƒ¡ áƒ›áƒ®áƒáƒ áƒ¡ áƒ£áƒáƒ áƒ§áƒáƒ¤áƒ˜áƒ— áƒ›áƒœáƒ˜áƒ¨áƒ•áƒœáƒ”áƒšáƒáƒ‘áƒ”áƒ‘áƒ¡.\n",
        "    train_df['Weekly_Sales'] = train_df['Weekly_Sales'].apply(lambda x: max(0, x))\n",
        "\n",
        "    # áƒ“áƒáƒ™áƒáƒ áƒ’áƒ£áƒšáƒ˜ áƒ›áƒœáƒ˜áƒ¨áƒ•áƒœáƒ”áƒšáƒáƒ‘áƒ”áƒ‘áƒ˜áƒ¡ áƒ“áƒáƒ›áƒ£áƒ¨áƒáƒ•áƒ”áƒ‘áƒ\n",
        "    # MarkDown-áƒ˜áƒ¡ áƒ¡áƒ•áƒ”áƒ¢áƒ”áƒ‘áƒ˜ áƒ®áƒ¨áƒ˜áƒ áƒáƒ“ áƒ¨áƒ”áƒ˜áƒªáƒáƒ•áƒ¡ NaN-áƒ”áƒ‘áƒ¡, áƒ áƒáƒ“áƒ’áƒáƒœ áƒáƒ¥áƒªáƒ˜áƒ”áƒ‘áƒ˜ áƒáƒ  áƒ§áƒáƒ¤áƒ˜áƒšáƒ.\n",
        "    # áƒ¨áƒ”áƒ•áƒáƒ•áƒ¡áƒáƒ— 0-áƒ”áƒ‘áƒ˜áƒ— áƒáƒœ áƒ¡áƒ®áƒ•áƒ áƒ¨áƒ”áƒ¡áƒáƒ‘áƒáƒ›áƒ˜áƒ¡áƒ˜ áƒ›áƒœáƒ˜áƒ¨áƒ•áƒœáƒ”áƒšáƒáƒ‘áƒ˜áƒ—.\n",
        "    markdown_cols = [col for col in train_df.columns if 'MarkDown' in col]\n",
        "    for col in markdown_cols:\n",
        "        train_df[col] = train_df[col].fillna(0)\n",
        "        test_df[col] = test_df[col].fillna(0)\n",
        "\n",
        "    # CPI, Unemployment, Temperature, Fuel_Price-áƒ˜áƒ¡ áƒ“áƒáƒ™áƒáƒ áƒ’áƒ£áƒšáƒ˜ áƒ›áƒœáƒ˜áƒ¨áƒ•áƒœáƒ”áƒšáƒáƒ‘áƒ”áƒ‘áƒ˜áƒ¡ áƒ¨áƒ”áƒ•áƒ¡áƒ”áƒ‘áƒ\n",
        "    # áƒ¨áƒ”áƒ•áƒáƒ•áƒ¡áƒáƒ— áƒ¬áƒ˜áƒœáƒ áƒ›áƒœáƒ˜áƒ¨áƒ•áƒœáƒ”áƒšáƒáƒ‘áƒ˜áƒ— áƒáƒœ áƒ¡áƒáƒ¨áƒ£áƒáƒšáƒáƒ—áƒ˜, áƒ áƒáƒ“áƒ’áƒáƒœ áƒ”áƒ¡ áƒ“áƒ áƒáƒ˜áƒ—áƒ˜ áƒ¡áƒ”áƒ áƒ˜áƒ”áƒ‘áƒ˜áƒ¡ áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ”áƒ‘áƒ˜áƒ.\n",
        "    for col in ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']:\n",
        "        train_df[col] = train_df[col].fillna(method='ffill').fillna(method='bfill')\n",
        "        test_df[col] = test_df[col].fillna(method='ffill').fillna(method='bfill')\n",
        "        # áƒ—áƒ£ áƒ›áƒáƒ˜áƒœáƒª áƒ“áƒáƒ áƒ©áƒ NaN (áƒ›áƒáƒ’. áƒ¡áƒ”áƒ áƒ˜áƒ˜áƒ¡ áƒ“áƒáƒ¡áƒáƒ¬áƒ§áƒ˜áƒ¡áƒ¨áƒ˜), áƒ¨áƒ”áƒ•áƒáƒ•áƒ¡áƒáƒ— áƒ¡áƒáƒ¨áƒ£áƒáƒšáƒáƒ—áƒ˜\n",
        "        train_df[col] = train_df[col].fillna(train_df[col].mean())\n",
        "        test_df[col] = test_df[col].fillna(test_df[col].mean())\n",
        "\n",
        "    # MLflow-áƒ¨áƒ˜ áƒšáƒáƒ’áƒ˜áƒ áƒ”áƒ‘áƒ\n",
        "    mlflow.log_param(\"initial_train_rows\", train_df.shape[0])\n",
        "    mlflow.log_param(\"initial_test_rows\", test_df.shape[0])\n",
        "    mlflow.log_param(\"regressors_used\", ', '.join(markdown_cols + ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']))\n",
        "\n",
        "    print(\"áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ—áƒ áƒ¬áƒ˜áƒœáƒáƒ¡áƒ¬áƒáƒ áƒ˜ áƒ“áƒáƒ›áƒ£áƒ¨áƒáƒ•áƒ”áƒ‘áƒ áƒ“áƒáƒ¡áƒ áƒ£áƒšáƒ“áƒ.\")\n",
        "    print(f\"áƒ“áƒáƒ›áƒ£áƒ¨áƒáƒ•áƒ”áƒ‘áƒ£áƒšáƒ˜ áƒ¡áƒáƒ¢áƒ áƒ”áƒœáƒ˜áƒœáƒ’áƒ áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ”áƒ‘áƒ˜áƒ¡ áƒœáƒ˜áƒ›áƒ£áƒ¨áƒ˜:\\n{train_df.head()}\")\n",
        "    print(f\"áƒ“áƒáƒ›áƒ£áƒ¨áƒáƒ•áƒ”áƒ‘áƒ£áƒšáƒ˜ áƒ¡áƒáƒ¢áƒ”áƒ¡áƒ¢áƒ áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ”áƒ‘áƒ˜áƒ¡ áƒœáƒ˜áƒ›áƒ£áƒ¨áƒ˜:\\n{test_df.head()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9n36ZebiN_0",
        "outputId": "66432766-c234-41ce-9bf2-27d7b9a1e14d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ—áƒ áƒ¬áƒ˜áƒœáƒáƒ¡áƒ¬áƒáƒ áƒ˜ áƒ“áƒáƒ›áƒ£áƒ¨áƒáƒ•áƒ”áƒ‘áƒ áƒ˜áƒ¬áƒ§áƒ”áƒ‘áƒ...\n",
            "áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ—áƒ áƒ¬áƒ˜áƒœáƒáƒ¡áƒ¬áƒáƒ áƒ˜ áƒ“áƒáƒ›áƒ£áƒ¨áƒáƒ•áƒ”áƒ‘áƒ áƒ“áƒáƒ¡áƒ áƒ£áƒšáƒ“áƒ.\n",
            "áƒ“áƒáƒ›áƒ£áƒ¨áƒáƒ•áƒ”áƒ‘áƒ£áƒšáƒ˜ áƒ¡áƒáƒ¢áƒ áƒ”áƒœáƒ˜áƒœáƒ’áƒ áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ”áƒ‘áƒ˜áƒ¡ áƒœáƒ˜áƒ›áƒ£áƒ¨áƒ˜:\n",
            "   Store  Dept       Date  Weekly_Sales  IsHoliday  Year  Month  Week  \\\n",
            "0      1     1 2010-02-05      24924.50      False  2010      2     5   \n",
            "1      1     1 2010-02-12      46039.49       True  2010      2     6   \n",
            "2      1     1 2010-02-19      41595.55      False  2010      2     7   \n",
            "3      1     1 2010-02-26      19403.54      False  2010      2     8   \n",
            "4      1     1 2010-03-05      21827.90      False  2010      3     9   \n",
            "\n",
            "   DayOfWeek  Super Bowl  ...  Fuel_Price  MarkDown1  MarkDown2  MarkDown3  \\\n",
            "0          4           0  ...       2.572        0.0        0.0        0.0   \n",
            "1          4           1  ...       2.548        0.0        0.0        0.0   \n",
            "2          4           0  ...       2.514        0.0        0.0        0.0   \n",
            "3          4           0  ...       2.561        0.0        0.0        0.0   \n",
            "4          4           0  ...       2.625        0.0        0.0        0.0   \n",
            "\n",
            "   MarkDown4  MarkDown5         CPI  Unemployment  Type    Size  \n",
            "0        0.0        0.0  211.096358         8.106     A  151315  \n",
            "1        0.0        0.0  211.242170         8.106     A  151315  \n",
            "2        0.0        0.0  211.289143         8.106     A  151315  \n",
            "3        0.0        0.0  211.319643         8.106     A  151315  \n",
            "4        0.0        0.0  211.350143         8.106     A  151315  \n",
            "\n",
            "[5 rows x 24 columns]\n",
            "áƒ“áƒáƒ›áƒ£áƒ¨áƒáƒ•áƒ”áƒ‘áƒ£áƒšáƒ˜ áƒ¡áƒáƒ¢áƒ”áƒ¡áƒ¢áƒ áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ”áƒ‘áƒ˜áƒ¡ áƒœáƒ˜áƒ›áƒ£áƒ¨áƒ˜:\n",
            "   Store  Dept       Date  IsHoliday  Year  Month  Week  DayOfWeek  \\\n",
            "0      1     1 2012-11-02      False  2012     11    44          4   \n",
            "1      1     1 2012-11-09      False  2012     11    45          4   \n",
            "2      1     1 2012-11-16      False  2012     11    46          4   \n",
            "3      1     1 2012-11-23       True  2012     11    47          4   \n",
            "4      1     1 2012-11-30      False  2012     11    48          4   \n",
            "\n",
            "   Super Bowl  Labor Day  ...  Fuel_Price  MarkDown1  MarkDown2  MarkDown3  \\\n",
            "0           0          0  ...       3.386    6766.44    5147.70      50.82   \n",
            "1           0          0  ...       3.314   11421.32    3370.89      40.28   \n",
            "2           0          0  ...       3.252    9696.28     292.10     103.78   \n",
            "3           0          0  ...       3.211     883.59       4.17   74910.32   \n",
            "4           0          0  ...       3.207    2460.03       0.00    3838.35   \n",
            "\n",
            "   MarkDown4  MarkDown5         CPI  Unemployment  Type    Size  \n",
            "0    3639.90    2737.42  223.462779         6.573     A  151315  \n",
            "1    4646.79    6154.16  223.481307         6.573     A  151315  \n",
            "2    1133.15    6612.69  223.512911         6.573     A  151315  \n",
            "3     209.91     303.32  223.561947         6.573     A  151315  \n",
            "4     150.57    6966.34  223.610984         6.573     A  151315  \n",
            "\n",
            "[5 rows x 23 columns]\n",
            "ğŸƒ View run Prophet_Cleaning at: https://dagshub.com/ekvirika/WalmartRecruiting.mlflow/#/experiments/0/runs/7978804592274e3c9093aa85d979e081\n",
            "ğŸ§ª View experiment at: https://dagshub.com/ekvirika/WalmartRecruiting.mlflow/#/experiments/0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ•áƒáƒ áƒ¯áƒ˜áƒ¨áƒ˜ áƒ“áƒ áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ áƒ§áƒ•áƒ”áƒšáƒ Store/Dept áƒ™áƒáƒ›áƒ‘áƒ˜áƒœáƒáƒªáƒ˜áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡ ---\n",
        "# áƒ›áƒ˜áƒ˜áƒ¦áƒ”áƒ— áƒ§áƒ•áƒ”áƒšáƒ áƒ£áƒœáƒ˜áƒ™áƒáƒšáƒ£áƒ áƒ˜ Store-Dept áƒ™áƒáƒ›áƒ‘áƒ˜áƒœáƒáƒªáƒ˜áƒ\n",
        "unique_store_dept_combinations = train_df[['Store', 'Dept']].drop_duplicates().values\n",
        "\n",
        "print(f\"áƒ¡áƒ£áƒš áƒ£áƒœáƒ˜áƒ™áƒáƒšáƒ£áƒ áƒ˜ Store-Dept áƒ™áƒáƒ›áƒ‘áƒ˜áƒœáƒáƒªáƒ˜áƒ”áƒ‘áƒ˜: {len(unique_store_dept_combinations)}\")\n",
        "\n",
        "# áƒ“áƒáƒ›áƒáƒ¢áƒ”áƒ‘áƒ˜áƒ—áƒ˜ áƒ áƒ”áƒ’áƒ áƒ”áƒ¡áƒáƒ áƒ”áƒ‘áƒ˜áƒ¡ áƒ›áƒáƒ›áƒ–áƒáƒ“áƒ”áƒ‘áƒ\n",
        "regressor_cols = ['IsHoliday', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment'] + markdown_cols\n",
        "\n",
        "for store_id, dept_id in unique_store_dept_combinations:\n",
        "    # áƒ¨áƒ”áƒ¥áƒ›áƒ”áƒœáƒ˜áƒ— áƒ›áƒ¨áƒáƒ‘áƒ”áƒšáƒ˜ áƒ’áƒáƒ¨áƒ•áƒ”áƒ‘áƒ áƒ—áƒ˜áƒ—áƒáƒ”áƒ£áƒšáƒ˜ Store/Dept áƒ™áƒáƒ›áƒ‘áƒ˜áƒœáƒáƒªáƒ˜áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡\n",
        "    with mlflow.start_run(run_name=f\"Prophet_Store_{store_id}_Dept_{dept_id}_Experiment\") as parent_run:\n",
        "        print(f\"\\n--- áƒ“áƒáƒ¬áƒ§áƒ”áƒ‘áƒ£áƒšáƒ˜áƒ áƒ”áƒ¥áƒ¡áƒáƒ”áƒ áƒ˜áƒ›áƒ”áƒœáƒ¢áƒ˜ Store {store_id}, Dept {dept_id}-áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡ ---\")\n",
        "\n",
        "        # áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ”áƒ‘áƒ˜áƒ¡ áƒ¤áƒ˜áƒšáƒ¢áƒ áƒáƒªáƒ˜áƒ áƒ›áƒ˜áƒ›áƒ“áƒ˜áƒœáƒáƒ áƒ” Store/Dept-áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡\n",
        "        train_filtered = train_df[(train_df['Store'] == store_id) & (train_df['Dept'] == dept_id)].copy()\n",
        "        test_filtered = test_df[(test_df['Store'] == store_id) & (test_df['Dept'] == dept_id)].copy()\n",
        "\n",
        "        # Prophet-áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡ áƒ¡áƒáƒ­áƒ˜áƒ áƒ áƒ¡áƒ•áƒ”áƒ¢áƒ”áƒ‘áƒ˜áƒ¡ áƒ’áƒáƒ“áƒáƒ áƒ¥áƒ›áƒ”áƒ•áƒ: 'ds' (áƒ—áƒáƒ áƒ˜áƒ¦áƒ˜) áƒ“áƒ 'y' (áƒ¡áƒáƒ›áƒ˜áƒ–áƒœáƒ”)\n",
        "        train_prophet_full = train_filtered[['Date', 'Weekly_Sales'] + regressor_cols].rename(columns={'Date': 'ds', 'Weekly_Sales': 'y'})\n",
        "        test_prophet_full = test_filtered[['Date'] + regressor_cols].rename(columns={'Date': 'ds'})\n",
        "\n",
        "        # áƒ“áƒáƒ áƒ¬áƒ›áƒ£áƒœáƒ“áƒ˜áƒ—, áƒ áƒáƒ› IsHoliday áƒáƒ áƒ˜áƒ¡ áƒ áƒ˜áƒªáƒ®áƒ•áƒ˜áƒ—áƒ˜\n",
        "        train_prophet_full['IsHoliday'] = train_prophet_full['IsHoliday'].astype(int)\n",
        "        test_prophet_full['IsHoliday'] = test_prophet_full['IsHoliday'].astype(int)\n",
        "\n",
        "        # áƒ¨áƒ”áƒáƒ›áƒáƒ¬áƒ›áƒ”áƒ—, áƒáƒ áƒ˜áƒ¡ áƒ—áƒ£ áƒáƒ áƒ áƒ¡áƒáƒ™áƒ›áƒáƒ áƒ˜áƒ¡áƒ˜ áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ”áƒ‘áƒ˜\n",
        "        if len(train_prophet_full) < 2: # Prophet-áƒ¡ áƒ›áƒ˜áƒœáƒ˜áƒ›áƒ£áƒ› 2 áƒ¬áƒ”áƒ áƒ¢áƒ˜áƒšáƒ˜ áƒ¡áƒ­áƒ˜áƒ áƒ“áƒ”áƒ‘áƒ\n",
        "            print(f\"áƒ’áƒáƒ›áƒáƒ¢áƒáƒ•áƒ”áƒ‘áƒ: áƒáƒ áƒáƒ¡áƒáƒ™áƒ›áƒáƒ áƒ˜áƒ¡áƒ˜ áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ”áƒ‘áƒ˜ Store {store_id}, Dept {dept_id}-áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡. (áƒ¡áƒ£áƒš {len(train_prophet_full)} áƒ©áƒáƒœáƒáƒ¬áƒ”áƒ áƒ˜)\")\n",
        "            mlflow.log_param(\"status\", \"skipped_insufficient_data\")\n",
        "            mlflow.log_param(\"num_records\", len(train_prophet_full))\n",
        "            continue # áƒ’áƒáƒ“áƒáƒ“áƒ˜áƒ— áƒ¨áƒ”áƒ›áƒ“áƒ”áƒ’ áƒ™áƒáƒ›áƒ‘áƒ˜áƒœáƒáƒªáƒ˜áƒáƒ–áƒ”\n",
        "\n",
        "        # --- 5.1. áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ•áƒáƒ áƒ¯áƒ˜áƒ¨áƒ˜ (Nested MLflow Run: Prophet_StoreX_DeptY_Training) ---\n",
        "        with mlflow.start_run(run_name=f\"Prophet_Store_{store_id}_Dept_{dept_id}_Training\", nested=True) as training_run:\n",
        "            print(f\"Prophet áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ•áƒáƒ áƒ¯áƒ˜áƒ¨áƒ˜ áƒ˜áƒ¬áƒ§áƒ”áƒ‘áƒ Store {store_id}, Dept {dept_id}-áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡...\")\n",
        "\n",
        "            # Prophet áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ˜áƒœáƒ˜áƒªáƒ˜áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ\n",
        "            model_params = {\n",
        "                'seasonality_mode': 'multiplicative',\n",
        "                'changepoint_prior_scale': 0.05,\n",
        "                'weekly_seasonality': True,\n",
        "                'daily_seasonality': False,\n",
        "                'yearly_seasonality': True\n",
        "            }\n",
        "\n",
        "            m = Prophet(**model_params)\n",
        "\n",
        "            # áƒ“áƒáƒ›áƒáƒ¢áƒ”áƒ‘áƒ˜áƒ—áƒ˜ áƒ áƒ”áƒ’áƒ áƒ”áƒ¡áƒáƒ áƒ”áƒ‘áƒ˜áƒ¡ áƒ“áƒáƒ›áƒáƒ¢áƒ”áƒ‘áƒ\n",
        "            for col in regressor_cols:\n",
        "                if col in train_prophet_full.columns and col in test_prophet_full.columns:\n",
        "                    m.add_regressor(col)\n",
        "                    mlflow.log_param(f\"regressor_{col}\", \"added\")\n",
        "                else:\n",
        "                    print(f\"áƒ’áƒáƒ¤áƒ áƒ—áƒ®áƒ˜áƒšáƒ”áƒ‘áƒ: áƒ áƒ”áƒ’áƒ áƒ”áƒ¡áƒáƒ áƒ˜ '{col}' áƒáƒ  áƒ›áƒáƒ˜áƒ«áƒ”áƒ‘áƒœáƒ áƒ§áƒ•áƒ”áƒšáƒ áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ—áƒ áƒœáƒáƒ™áƒ áƒ”áƒ‘áƒ¨áƒ˜ Store {store_id}, Dept {dept_id}-áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡.\")\n",
        "\n",
        "            # áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ•áƒáƒ áƒ¯áƒ˜áƒ¨áƒ˜\n",
        "            m.fit(train_prophet_full)\n",
        "\n",
        "            print(f\"Prophet áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ•áƒáƒ áƒ¯áƒ˜áƒ¨áƒ˜ áƒ“áƒáƒ¡áƒ áƒ£áƒšáƒ“áƒ Store {store_id}, Dept {dept_id}-áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡.\")\n",
        "\n",
        "            # MLflow-áƒ¨áƒ˜ áƒáƒáƒ áƒáƒ›áƒ”áƒ¢áƒ áƒ”áƒ‘áƒ˜áƒ¡ áƒ“áƒ áƒšáƒáƒ’áƒ˜áƒ áƒ”áƒ‘áƒ\n",
        "            for param, value in model_params.items():\n",
        "                mlflow.log_param(param, value)\n",
        "            mlflow.log_param(\"filtered_store_id\", store_id)\n",
        "            mlflow.log_param(\"filtered_dept_id\", dept_id)\n",
        "            mlflow.log_param(\"final_train_rows_prophet\", train_prophet_full.shape[0])\n",
        "            mlflow.log_param(\"final_test_rows_prophet\", test_prophet_full.shape[0])\n",
        "\n",
        "            # áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ¨áƒ”áƒœáƒáƒ®áƒ•áƒ MLflow-áƒ¨áƒ˜\n",
        "            mlflow.pyfunc.log_model(\n",
        "                artifact_path=\"prophet_model\",\n",
        "                python_model=mlflow.pyfunc.PythonModel(),\n",
        "                artifacts={\"prophet_model\": m},\n",
        "                # code_path=[__file__],\n",
        "                conda_env={\n",
        "                    \"channels\": [\"defaults\", \"conda-forge\"],\n",
        "                    \"dependencies\": [\n",
        "                        \"python=3.9\", # áƒ¨áƒ”áƒªáƒ•áƒáƒšáƒ”áƒ— áƒ—áƒ¥áƒ•áƒ”áƒœáƒ˜ python áƒ•áƒ”áƒ áƒ¡áƒ˜áƒ˜áƒ—\n",
        "                        \"pandas\",\n",
        "                        \"numpy\",\n",
        "                        \"prophet\",\n",
        "                        \"scikit-learn\",\n",
        "                        \"matplotlib\",\n",
        "                        \"plotly\",\n",
        "                        \"mlflow\"\n",
        "                    ]\n",
        "                }\n",
        "            )\n",
        "            print(f\"Prophet áƒ›áƒáƒ“áƒ”áƒšáƒ˜ áƒ¨áƒ”áƒœáƒáƒ®áƒ£áƒšáƒ˜áƒ MLflow-áƒ¨áƒ˜ Store {store_id}, Dept {dept_id}-áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡.\")\n",
        "\n",
        "            # áƒáƒ áƒáƒ’áƒœáƒáƒ–áƒ˜áƒ áƒ”áƒ‘áƒ áƒ¡áƒáƒ¢áƒ áƒ”áƒœáƒ˜áƒœáƒ’áƒ áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ”áƒ‘áƒ–áƒ” (áƒ•áƒ˜áƒ–áƒ£áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡)\n",
        "            forecast_train = m.predict(train_prophet_full[['ds'] + [col for col in regressor_cols if col in train_prophet_full.columns]])\n",
        "\n",
        "            # áƒ•áƒ˜áƒ–áƒ£áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ\n",
        "            fig = m.plot(forecast_train)\n",
        "            plt.title(f\"Prophet áƒáƒ áƒáƒ’áƒœáƒáƒ–áƒ˜ (Store {store_id}, Dept {dept_id})\")\n",
        "            plt.xlabel(\"áƒ—áƒáƒ áƒ˜áƒ¦áƒ˜\")\n",
        "            plt.ylabel(\"áƒ™áƒ•áƒ˜áƒ áƒ˜áƒ¡ áƒ’áƒáƒ§áƒ˜áƒ“áƒ•áƒ”áƒ‘áƒ˜\")\n",
        "            mlflow.log_figure(fig, \"prophet_forecast_train.png\")\n",
        "            plt.close(fig)\n",
        "\n",
        "            # áƒ™áƒáƒ›áƒáƒáƒœáƒ”áƒœáƒ¢áƒ”áƒ‘áƒ˜áƒ¡ áƒ•áƒ˜áƒ–áƒ£áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ\n",
        "            fig2 = m.plot_components(forecast_train)\n",
        "            mlflow.log_figure(fig2, \"prophet_components.png\")\n",
        "            plt.close(fig2)\n",
        "\n",
        "            # --- 5.2. áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ (Nested MLflow Run: Prophet_StoreX_DeptY_Cross_Validation) ---\n",
        "            with mlflow.start_run(run_name=f\"Prophet_Store_{store_id}_Dept_{dept_id}_Cross_Validation\", nested=True) as cv_run:\n",
        "                print(f\"Prophet áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ áƒ˜áƒ¬áƒ§áƒ”áƒ‘áƒ Store {store_id}, Dept {dept_id}-áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡...\")\n",
        "\n",
        "                # áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ˜áƒ¡ áƒáƒáƒ áƒáƒ›áƒ”áƒ¢áƒ áƒ”áƒ‘áƒ˜\n",
        "                # initial: áƒ¡áƒáƒ¬áƒ§áƒ˜áƒ¡áƒ˜ áƒ¡áƒáƒ¢áƒ áƒ”áƒœáƒ˜áƒœáƒ’áƒ áƒáƒ”áƒ áƒ˜áƒáƒ“áƒ˜\n",
        "                # period: áƒ§áƒáƒ•áƒ”áƒšáƒ˜ áƒ¨áƒ”áƒ›áƒ“áƒ’áƒáƒ›áƒ˜ áƒ’áƒáƒ¤áƒáƒ áƒ—áƒáƒ”áƒ‘áƒ˜áƒ¡ áƒáƒ”áƒ áƒ˜áƒáƒ“áƒ˜\n",
        "                # horizon: áƒáƒ áƒáƒ’áƒœáƒáƒ–áƒ˜áƒ¡ áƒ°áƒáƒ áƒ˜áƒ–áƒáƒœáƒ¢áƒ˜\n",
        "                # áƒ“áƒáƒ áƒ¬áƒ›áƒ£áƒœáƒ“áƒ˜áƒ—, áƒ áƒáƒ› initial áƒ¡áƒáƒ™áƒ›áƒáƒ áƒ˜áƒ¡áƒáƒ“ áƒ“áƒ˜áƒ“áƒ˜áƒ.\n",
        "                # Prophet-áƒ˜áƒ¡ áƒ“áƒáƒ™áƒ£áƒ›áƒ”áƒœáƒ¢áƒáƒªáƒ˜áƒ áƒ’áƒ•áƒ˜áƒ áƒ©áƒ”áƒ•áƒ¡ áƒ›áƒ˜áƒœáƒ˜áƒ›áƒ£áƒ› 20-áƒ¯áƒ”áƒ  áƒ°áƒáƒ áƒ˜áƒ–áƒáƒœáƒ¢áƒ˜áƒ¡ áƒ–áƒáƒ›áƒ.\n",
        "                # áƒ—áƒ£ áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ”áƒ‘áƒ˜ áƒ›áƒªáƒ˜áƒ áƒ”áƒ, áƒ”áƒ¡ áƒ¨áƒ”áƒ˜áƒ«áƒšáƒ”áƒ‘áƒ áƒ’áƒáƒ›áƒáƒ˜áƒ¬áƒ•áƒ˜áƒáƒ¡ áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ.\n",
        "                # áƒ•áƒªáƒáƒ“áƒáƒ— áƒ“áƒ˜áƒœáƒáƒ›áƒ˜áƒ£áƒ áƒ˜ initial\n",
        "                min_initial_weeks = 20 # Prophet-áƒ˜áƒ¡ áƒ áƒ”áƒ™áƒáƒ›áƒ”áƒœáƒ“áƒáƒªáƒ˜áƒ\n",
        "                initial_weeks = max(min_initial_weeks, int(len(train_prophet_full) * 0.7)) # áƒ›áƒ˜áƒœáƒ˜áƒ›áƒ£áƒ› 70% áƒáƒœ 20 áƒ™áƒ•áƒ˜áƒ áƒ\n",
        "                cv_initial = f\"{initial_weeks} W\"\n",
        "                cv_period = \"4 W\"\n",
        "                cv_horizon = \"12 W\"\n",
        "\n",
        "                print(f\"áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ˜áƒ¡ áƒáƒáƒ áƒáƒ›áƒ”áƒ¢áƒ áƒ”áƒ‘áƒ˜: initial={cv_initial}, period={cv_period}, horizon={cv_horizon}\")\n",
        "\n",
        "                # MLflow-áƒ¨áƒ˜ áƒšáƒáƒ’áƒ˜áƒ áƒ”áƒ‘áƒ\n",
        "                mlflow.log_param(\"cv_initial\", cv_initial)\n",
        "                mlflow.log_param(\"cv_period\", cv_period)\n",
        "                mlflow.log_param(\"cv_horizon\", cv_horizon)\n",
        "\n",
        "                # áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ˜áƒ¡ áƒ’áƒáƒ¨áƒ•áƒ”áƒ‘áƒ\n",
        "                try:\n",
        "                    df_cv = cross_validation(\n",
        "                        m,\n",
        "                        initial=cv_initial,\n",
        "                        period=cv_period,\n",
        "                        horizon=cv_horizon,\n",
        "                        cutoffs=None,\n",
        "                        parallel=\"processes\"\n",
        "                    )\n",
        "                    print(\"áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ áƒ“áƒáƒ¡áƒ áƒ£áƒšáƒ“áƒ.\")\n",
        "                    print(f\"áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ˜áƒ¡ áƒ¨áƒ”áƒ“áƒ”áƒ’áƒ”áƒ‘áƒ˜áƒ¡ áƒœáƒ˜áƒ›áƒ£áƒ¨áƒ˜:\\n{df_cv.head()}\")\n",
        "\n",
        "                    # áƒ¨áƒ”áƒ¡áƒ áƒ£áƒšáƒ”áƒ‘áƒ˜áƒ¡ áƒ›áƒ”áƒ¢áƒ áƒ˜áƒ™áƒ”áƒ‘áƒ˜áƒ¡ áƒ’áƒáƒ›áƒáƒ—áƒ•áƒšáƒ\n",
        "                    df_p = performance_metrics(df_cv)\n",
        "                    print(f\"áƒ¨áƒ”áƒ¡áƒ áƒ£áƒšáƒ”áƒ‘áƒ˜áƒ¡ áƒ›áƒ”áƒ¢áƒ áƒ˜áƒ™áƒ”áƒ‘áƒ˜áƒ¡ áƒœáƒ˜áƒ›áƒ£áƒ¨áƒ˜:\\n{df_p.head()}\")\n",
        "\n",
        "                    # áƒ¨áƒ”áƒ¤áƒáƒ¡áƒ”áƒ‘áƒ˜áƒ¡ áƒ›áƒ”áƒ¢áƒ áƒ˜áƒ™áƒ”áƒ‘áƒ˜áƒ¡ áƒšáƒáƒ’áƒ˜áƒ áƒ”áƒ‘áƒ MLflow-áƒ¨áƒ˜\n",
        "                    mlflow.log_metric(\"mae_cv_mean\", df_p['mae'].mean())\n",
        "                    mlflow.log_metric(\"rmse_cv_mean\", df_p['rmse'].mean())\n",
        "                    mlflow.log_metric(\"mape_cv_mean\", df_p['mape'].mean())\n",
        "                    mlflow.log_metric(\"smape_cv_mean\", df_p['smape'].mean())\n",
        "\n",
        "                    # áƒ•áƒ˜áƒ–áƒ£áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ: áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ˜áƒ¡ áƒ›áƒ”áƒ¢áƒ áƒ˜áƒ™áƒ”áƒ‘áƒ˜ áƒ“áƒ áƒáƒ˜áƒ¡ áƒ›áƒ˜áƒ®áƒ”áƒ“áƒ•áƒ˜áƒ—\n",
        "                    fig_metrics = make_subplots(rows=2, cols=1, shared_xaxes=True,\n",
        "                                                subplot_titles=(\"MAE áƒ“áƒ áƒáƒ˜áƒ¡ áƒ›áƒ˜áƒ®áƒ”áƒ“áƒ•áƒ˜áƒ—\", \"RMSE áƒ“áƒ áƒáƒ˜áƒ¡ áƒ›áƒ˜áƒ®áƒ”áƒ“áƒ•áƒ˜áƒ—\"))\n",
        "                    fig_metrics.add_trace(go.Scatter(x=df_p['horizon'], y=df_p['mae'], mode='lines', name='MAE'), row=1, col=1)\n",
        "                    fig_metrics.add_trace(go.Scatter(x=df_p['horizon'], y=df_p['rmse'], mode='lines', name='RMSE'), row=2, col=1)\n",
        "                    fig_metrics.update_layout(title_text=f\"Prophet áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ˜áƒ¡ áƒ›áƒ”áƒ¢áƒ áƒ˜áƒ™áƒ”áƒ‘áƒ˜ (Store {store_id}, Dept {dept_id})\", height=600)\n",
        "                    mlflow.log_figure(fig_metrics, \"prophet_cv_metrics.png\")\n",
        "\n",
        "                except ValueError as e:\n",
        "                    print(f\"áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ˜áƒ¡áƒáƒ¡ Store {store_id}, Dept {dept_id}-áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡: {e}\")\n",
        "                    print(\"áƒ”áƒ¡ áƒ¨áƒ”áƒ˜áƒ«áƒšáƒ”áƒ‘áƒ áƒ›áƒáƒ®áƒ“áƒ”áƒ¡, áƒ—áƒ£ áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ—áƒ áƒœáƒáƒ™áƒ áƒ”áƒ‘áƒ˜ áƒ«áƒáƒšáƒ˜áƒáƒœ áƒ›áƒªáƒ˜áƒ áƒ”áƒ áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡ áƒ›áƒ˜áƒ—áƒ˜áƒ—áƒ”áƒ‘áƒ£áƒšáƒ˜ áƒáƒáƒ áƒáƒ›áƒ”áƒ¢áƒ áƒ”áƒ‘áƒ˜áƒ—.\")\n",
        "                    mlflow.log_param(\"cv_error\", str(e))\n",
        "                except Exception as e:\n",
        "                    print(f\"áƒ›áƒáƒ£áƒšáƒáƒ“áƒœáƒ”áƒšáƒ˜ áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ˜áƒ¡áƒáƒ¡ Store {store_id}, Dept {dept_id}-áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡: {e}\")\n",
        "                    mlflow.log_param(\"cv_error\", str(e))\n",
        "\n",
        "            # --- 5.3. áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ áƒ”áƒ’áƒ˜áƒ¡áƒ¢áƒ áƒáƒªáƒ˜áƒ (MLflow Model Registry) ---\n",
        "            # áƒ áƒ”áƒ’áƒ˜áƒ¡áƒ¢áƒ áƒáƒªáƒ˜áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡ áƒ¡áƒáƒ­áƒ˜áƒ áƒáƒ run_id, áƒ¡áƒáƒ˜áƒ“áƒáƒœáƒáƒª áƒ›áƒáƒ“áƒ”áƒšáƒ˜ áƒ“áƒáƒ˜áƒšáƒáƒ’áƒ.\n",
        "            try:\n",
        "                registered_model = mlflow.register_model(\n",
        "                    model_uri=f\"runs:/{training_run.info.run_id}/prophet_model\",\n",
        "                    name=f\"WalmartSalesProphetModel_Store_{store_id}_Dept_{dept_id}\"\n",
        "                )\n",
        "                print(f\"áƒ›áƒáƒ“áƒ”áƒšáƒ˜ 'WalmartSalesProphetModel_Store_{store_id}_Dept_{dept_id}' áƒ¬áƒáƒ áƒ›áƒáƒ¢áƒ”áƒ‘áƒ˜áƒ— áƒ“áƒáƒ áƒ”áƒ’áƒ˜áƒ¡áƒ¢áƒ áƒ˜áƒ áƒ“áƒ Model Registry-áƒ¨áƒ˜.\")\n",
        "                print(f\"áƒ•áƒ”áƒ áƒ¡áƒ˜áƒ: {registered_model.version}\")\n",
        "            except Exception as e:\n",
        "                print(f\"áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ áƒ”áƒ’áƒ˜áƒ¡áƒ¢áƒ áƒáƒªáƒ˜áƒ˜áƒ¡áƒáƒ¡ Store {store_id}, Dept {dept_id}-áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡: {e}\")\n",
        "                print(\"áƒ“áƒáƒ áƒ¬áƒ›áƒ£áƒœáƒ“áƒ˜áƒ—, áƒ áƒáƒ› MLflow Tracking Server áƒ’áƒáƒ¨áƒ•áƒ”áƒ‘áƒ£áƒšáƒ˜áƒ áƒ“áƒ áƒ’áƒáƒ¥áƒ•áƒ— áƒ¬áƒ•áƒ“áƒáƒ›áƒ Model Registry-áƒ–áƒ”.\")\n",
        "\n",
        "print(\"\\náƒ§áƒ•áƒ”áƒšáƒ Prophet áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ”áƒ¥áƒ¡áƒáƒ”áƒ áƒ˜áƒ›áƒ”áƒœáƒ¢áƒ˜ áƒ“áƒáƒ¡áƒ áƒ£áƒšáƒ“áƒ.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724
        },
        "id": "yXHqhiNAh-H8",
        "outputId": "083cb135-1ece-44e4-ae35-f969c20464ce"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "áƒ¡áƒ£áƒš áƒ£áƒœáƒ˜áƒ™áƒáƒšáƒ£áƒ áƒ˜ Store-Dept áƒ™áƒáƒ›áƒ‘áƒ˜áƒœáƒáƒªáƒ˜áƒ”áƒ‘áƒ˜: 3331\n",
            "\n",
            "--- áƒ“áƒáƒ¬áƒ§áƒ”áƒ‘áƒ£áƒšáƒ˜áƒ áƒ”áƒ¥áƒ¡áƒáƒ”áƒ áƒ˜áƒ›áƒ”áƒœáƒ¢áƒ˜ Store 1, Dept 1-áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡ ---\n",
            "Prophet áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ•áƒáƒ áƒ¯áƒ˜áƒ¨áƒ˜ áƒ˜áƒ¬áƒ§áƒ”áƒ‘áƒ Store 1, Dept 1-áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmphqh0gn0f/5tdcfd8l.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmphqh0gn0f/75gtmayj.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.11/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=82078', 'data', 'file=/tmp/tmphqh0gn0f/5tdcfd8l.json', 'init=/tmp/tmphqh0gn0f/75gtmayj.json', 'output', 'file=/tmp/tmphqh0gn0f/prophet_modelo8couty8/prophet_model-20250707203545.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "20:35:45 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "20:35:45 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prophet áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ•áƒáƒ áƒ¯áƒ˜áƒ¨áƒ˜ áƒ“áƒáƒ¡áƒ áƒ£áƒšáƒ“áƒ Store 1, Dept 1-áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/07/07 20:35:53 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸƒ View run Prophet_Store_1_Dept_1_Training at: https://dagshub.com/ekvirika/WalmartRecruiting.mlflow/#/experiments/0/runs/69b68899f52d459a9f8b89756fb7b45b\n",
            "ğŸ§ª View experiment at: https://dagshub.com/ekvirika/WalmartRecruiting.mlflow/#/experiments/0\n",
            "ğŸƒ View run Prophet_Store_1_Dept_1_Experiment at: https://dagshub.com/ekvirika/WalmartRecruiting.mlflow/#/experiments/0/runs/70e872430f584da3bd3df1c8d2602381\n",
            "ğŸ§ª View experiment at: https://dagshub.com/ekvirika/WalmartRecruiting.mlflow/#/experiments/0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RestException",
          "evalue": "INTERNAL_ERROR: Response: {'error': 'unsupported endpoint, please contact support@dagshub.com'}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRestException\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-26-1955765777.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ¨áƒ”áƒœáƒáƒ®áƒ•áƒ MLflow-áƒ¨áƒ˜\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             mlflow.pyfunc.log_model(\n\u001b[0m\u001b[1;32m     72\u001b[0m                 \u001b[0martifact_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"prophet_model\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mpython_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/tracing/provider.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                     \u001b[0mis_func_called\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/pyfunc/__init__.py\u001b[0m in \u001b[0;36mlog_model\u001b[0;34m(artifact_path, loader_module, data_path, code_paths, infer_code_paths, conda_env, python_model, artifacts, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, metadata, model_config, streamable, resources, auth_policy, prompts, name, params, tags, model_type, step, model_id)\u001b[0m\n\u001b[1;32m   3577\u001b[0m         \u001b[0mmetadata\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlogged\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3578\u001b[0m     \"\"\"\n\u001b[0;32m-> 3579\u001b[0;31m     return Model.log(\n\u001b[0m\u001b[1;32m   3580\u001b[0m         \u001b[0martifact_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3581\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/models/model.py\u001b[0m in \u001b[0;36mlog\u001b[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, auth_policy, prompts, name, model_type, params, tags, step, model_id, **kwargs)\u001b[0m\n\u001b[1;32m   1159\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_id\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 }\n\u001b[0;32m-> 1161\u001b[0;31m                 model = mlflow.initialize_logged_model(\n\u001b[0m\u001b[1;32m   1162\u001b[0m                     \u001b[0;31m# TODO: Update model name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/tracking/fluent.py\u001b[0m in \u001b[0;36minitialize_logged_model\u001b[0;34m(name, source_run_id, tags, params, model_type, experiment_id)\u001b[0m\n\u001b[1;32m   2128\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mnew\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mpy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoggedModel\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mPENDING\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2129\u001b[0m     \"\"\"\n\u001b[0;32m-> 2130\u001b[0;31m     model = _create_logged_model(\n\u001b[0m\u001b[1;32m   2131\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m         \u001b[0msource_run_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource_run_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/tracking/fluent.py\u001b[0m in \u001b[0;36m_create_logged_model\u001b[0;34m(name, source_run_id, tags, params, model_type, experiment_id)\u001b[0m\n\u001b[1;32m   2255\u001b[0m         )\n\u001b[1;32m   2256\u001b[0m     \u001b[0mresolved_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2257\u001b[0;31m     return MlflowClient().create_logged_model(\n\u001b[0m\u001b[1;32m   2258\u001b[0m         \u001b[0mexperiment_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2259\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/tracking/client.py\u001b[0m in \u001b[0;36mcreate_logged_model\u001b[0;34m(self, experiment_id, name, source_run_id, tags, params, model_type)\u001b[0m\n\u001b[1;32m   5369\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mcreated\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5370\u001b[0m         \"\"\"\n\u001b[0;32m-> 5371\u001b[0;31m         return self._tracking_client.create_logged_model(\n\u001b[0m\u001b[1;32m   5372\u001b[0m             \u001b[0mexperiment_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_run_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5373\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/tracking/_tracking_service/client.py\u001b[0m in \u001b[0;36mcreate_logged_model\u001b[0;34m(self, experiment_id, name, source_run_id, tags, params, model_type)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0mmodel_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     ) -> LoggedModel:\n\u001b[0;32m--> 824\u001b[0;31m         return self.store.create_logged_model(\n\u001b[0m\u001b[1;32m    825\u001b[0m             \u001b[0mexperiment_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/store/tracking/rest_store.py\u001b[0m in \u001b[0;36mcreate_logged_model\u001b[0;34m(self, experiment_id, name, source_run_id, tags, params, model_type)\u001b[0m\n\u001b[1;32m    934\u001b[0m         )\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mresponse_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCreateLoggedModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoggedModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/store/tracking/rest_store.py\u001b[0m in \u001b[0;36m_call_endpoint\u001b[0;34m(self, api, json_body, endpoint, retry_timeout_seconds)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_METHOD_TO_INFO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mresponse_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         return call_endpoint(\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_host_creds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/utils/rest_utils.py\u001b[0m in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers, retry_timeout_seconds)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverify_rest_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m     \u001b[0mresponse_to_parse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/utils/rest_utils.py\u001b[0m in \u001b[0;36mverify_rest_response\u001b[0;34m(response, endpoint)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_can_parse_as_json_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRestException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             base_msg = (\n",
            "\u001b[0;31mRestException\u001b[0m: INTERNAL_ERROR: Response: {'error': 'unsupported endpoint, please contact support@dagshub.com'}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- 6. áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ (MLflow Run: Prophet_Cross_Validation) ---\n",
        "with mlflow.start_run(run_name=\"Prophet_Cross_Validation\", nested=True) as cv_run:\n",
        "    print(\"Prophet áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ áƒ˜áƒ¬áƒ§áƒ”áƒ‘áƒ...\")\n",
        "\n",
        "    # áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ˜áƒ¡ áƒáƒáƒ áƒáƒ›áƒ”áƒ¢áƒ áƒ”áƒ‘áƒ˜\n",
        "    # initial: áƒ¡áƒáƒ¬áƒ§áƒ˜áƒ¡áƒ˜ áƒ¡áƒáƒ¢áƒ áƒ”áƒœáƒ˜áƒœáƒ’áƒ áƒáƒ”áƒ áƒ˜áƒáƒ“áƒ˜\n",
        "    # period: áƒ§áƒáƒ•áƒ”áƒšáƒ˜ áƒ¨áƒ”áƒ›áƒ“áƒ’áƒáƒ›áƒ˜ áƒ’áƒáƒ¤áƒáƒ áƒ—áƒáƒ”áƒ‘áƒ˜áƒ¡ áƒáƒ”áƒ áƒ˜áƒáƒ“áƒ˜\n",
        "    # horizon: áƒáƒ áƒáƒ’áƒœáƒáƒ–áƒ˜áƒ¡ áƒ°áƒáƒ áƒ˜áƒ–áƒáƒœáƒ¢áƒ˜\n",
        "    cv_initial = f\"{int(len(train_prophet_full) * 0.7)} W\" # 70% áƒ¡áƒáƒ¬áƒ§áƒ˜áƒ¡áƒ˜ áƒ¢áƒ áƒ”áƒœáƒ˜áƒœáƒ’áƒ˜\n",
        "    cv_period = \"4 W\" # áƒ§áƒáƒ•áƒ”áƒš 4 áƒ™áƒ•áƒ˜áƒ áƒáƒ¨áƒ˜\n",
        "    cv_horizon = \"12 W\" # 12 áƒ™áƒ•áƒ˜áƒ áƒ˜áƒáƒœáƒ˜ áƒáƒ áƒáƒ’áƒœáƒáƒ–áƒ˜\n",
        "\n",
        "    print(f\"áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ˜áƒ¡ áƒáƒáƒ áƒáƒ›áƒ”áƒ¢áƒ áƒ”áƒ‘áƒ˜: initial={cv_initial}, period={cv_period}, horizon={cv_horizon}\")\n",
        "\n",
        "    # MLflow-áƒ¨áƒ˜ áƒšáƒáƒ’áƒ˜áƒ áƒ”áƒ‘áƒ\n",
        "    mlflow.log_param(\"cv_initial\", cv_initial)\n",
        "    mlflow.log_param(\"cv_period\", cv_period)\n",
        "    mlflow.log_param(\"cv_horizon\", cv_horizon)\n",
        "\n",
        "    # áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ˜áƒ¡ áƒ’áƒáƒ¨áƒ•áƒ”áƒ‘áƒ\n",
        "    try:\n",
        "        df_cv = cross_validation(\n",
        "            m,\n",
        "            initial=cv_initial,\n",
        "            period=cv_period,\n",
        "            horizon=cv_horizon,\n",
        "            cutoffs=None, # áƒáƒ•áƒ¢áƒáƒ›áƒáƒ¢áƒ£áƒ áƒ˜ cutoffs\n",
        "            parallel=\"processes\" # áƒáƒáƒ áƒáƒšáƒ”áƒšáƒ£áƒ áƒ˜ áƒ¨áƒ”áƒ¡áƒ áƒ£áƒšáƒ”áƒ‘áƒ\n",
        "        )\n",
        "        print(\"áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ áƒ“áƒáƒ¡áƒ áƒ£áƒšáƒ“áƒ.\")\n",
        "        print(f\"áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ˜áƒ¡ áƒ¨áƒ”áƒ“áƒ”áƒ’áƒ”áƒ‘áƒ˜áƒ¡ áƒœáƒ˜áƒ›áƒ£áƒ¨áƒ˜:\\n{df_cv.head()}\")\n",
        "\n",
        "        # áƒ¨áƒ”áƒ¡áƒ áƒ£áƒšáƒ”áƒ‘áƒ˜áƒ¡ áƒ›áƒ”áƒ¢áƒ áƒ˜áƒ™áƒ”áƒ‘áƒ˜áƒ¡ áƒ’áƒáƒ›áƒáƒ—áƒ•áƒšáƒ\n",
        "        df_p = performance_metrics(df_cv)\n",
        "        print(f\"áƒ¨áƒ”áƒ¡áƒ áƒ£áƒšáƒ”áƒ‘áƒ˜áƒ¡ áƒ›áƒ”áƒ¢áƒ áƒ˜áƒ™áƒ”áƒ‘áƒ˜áƒ¡ áƒœáƒ˜áƒ›áƒ£áƒ¨áƒ˜:\\n{df_p.head()}\")\n",
        "\n",
        "        # áƒ¨áƒ”áƒ¤áƒáƒ¡áƒ”áƒ‘áƒ˜áƒ¡ áƒ›áƒ”áƒ¢áƒ áƒ˜áƒ™áƒ”áƒ‘áƒ˜áƒ¡ áƒšáƒáƒ’áƒ˜áƒ áƒ”áƒ‘áƒ MLflow-áƒ¨áƒ˜\n",
        "        mlflow.log_metric(\"mae_cv_mean\", df_p['mae'].mean())\n",
        "        mlflow.log_metric(\"rmse_cv_mean\", df_p['rmse'].mean())\n",
        "        mlflow.log_metric(\"mape_cv_mean\", df_p['mape'].mean())\n",
        "        mlflow.log_metric(\"smape_cv_mean\", df_p['smape'].mean())\n",
        "\n",
        "        # áƒ•áƒ˜áƒ–áƒ£áƒáƒšáƒ˜áƒ–áƒáƒªáƒ˜áƒ: áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ˜áƒ¡ áƒ›áƒ”áƒ¢áƒ áƒ˜áƒ™áƒ”áƒ‘áƒ˜ áƒ“áƒ áƒáƒ˜áƒ¡ áƒ›áƒ˜áƒ®áƒ”áƒ“áƒ•áƒ˜áƒ—\n",
        "        fig_metrics = make_subplots(rows=2, cols=1, shared_xaxes=True,\n",
        "                                    subplot_titles=(\"MAE áƒ“áƒ áƒáƒ˜áƒ¡ áƒ›áƒ˜áƒ®áƒ”áƒ“áƒ•áƒ˜áƒ—\", \"RMSE áƒ“áƒ áƒáƒ˜áƒ¡ áƒ›áƒ˜áƒ®áƒ”áƒ“áƒ•áƒ˜áƒ—\"))\n",
        "        fig_metrics.add_trace(go.Scatter(x=df_p['horizon'], y=df_p['mae'], mode='lines', name='MAE'), row=1, col=1)\n",
        "        fig_metrics.add_trace(go.Scatter(x=df_p['horizon'], y=df_p['rmse'], mode='lines', name='RMSE'), row=2, col=1)\n",
        "        fig_metrics.update_layout(title_text=\"Prophet áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ˜áƒ¡ áƒ›áƒ”áƒ¢áƒ áƒ˜áƒ™áƒ”áƒ‘áƒ˜\", height=600)\n",
        "        mlflow.log_figure(fig_metrics, \"prophet_cv_metrics.png\")\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ˜áƒ¡áƒáƒ¡: {e}\")\n",
        "        print(\"áƒ”áƒ¡ áƒ¨áƒ”áƒ˜áƒ«áƒšáƒ”áƒ‘áƒ áƒ›áƒáƒ®áƒ“áƒ”áƒ¡, áƒ—áƒ£ áƒ›áƒáƒœáƒáƒªáƒ”áƒ›áƒ—áƒ áƒœáƒáƒ™áƒ áƒ”áƒ‘áƒ˜ áƒ«áƒáƒšáƒ˜áƒáƒœ áƒ›áƒªáƒ˜áƒ áƒ”áƒ áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡ áƒ›áƒ˜áƒ—áƒ˜áƒ—áƒ”áƒ‘áƒ£áƒšáƒ˜ áƒáƒáƒ áƒáƒ›áƒ”áƒ¢áƒ áƒ”áƒ‘áƒ˜áƒ—.\")\n",
        "        mlflow.log_param(\"cv_error\", str(e))\n",
        "    except Exception as e:\n",
        "        print(f\"áƒ›áƒáƒ£áƒšáƒáƒ“áƒœáƒ”áƒšáƒ˜ áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ áƒ™áƒ áƒáƒ¡-áƒ•áƒáƒšáƒ˜áƒ“áƒáƒªáƒ˜áƒ˜áƒ¡áƒáƒ¡: {e}\")\n",
        "        mlflow.log_param(\"cv_error\", str(e))\n",
        "\n",
        "print(\"Prophet áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ”áƒ¥áƒ¡áƒáƒ”áƒ áƒ˜áƒ›áƒ”áƒœáƒ¢áƒ˜ áƒ“áƒáƒ¡áƒ áƒ£áƒšáƒ“áƒ.\")\n"
      ],
      "metadata": {
        "id": "aunCbvW7iV2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- 7. áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ áƒ”áƒ’áƒ˜áƒ¡áƒ¢áƒ áƒáƒªáƒ˜áƒ (MLflow Model Registry) ---\n",
        "# áƒ”áƒ¡ áƒœáƒáƒ‘áƒ˜áƒ¯áƒ˜ áƒ£áƒœáƒ“áƒ áƒ¨áƒ”áƒ¡áƒ áƒ£áƒšáƒ“áƒ”áƒ¡ áƒ›áƒ®áƒáƒšáƒáƒ“ áƒ¡áƒáƒ£áƒ™áƒ”áƒ—áƒ”áƒ¡áƒ áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡.\n",
        "# áƒáƒ› áƒœáƒáƒ£áƒ—áƒ‘áƒ£áƒ¥áƒ¨áƒ˜, áƒ©áƒ•áƒ”áƒœ áƒ•áƒ áƒ”áƒ’áƒ˜áƒ¡áƒ¢áƒ áƒ˜áƒ áƒ”áƒ‘áƒ— Prophet áƒ›áƒáƒ“áƒ”áƒšáƒ¡.\n",
        "# model_inference.ipynb áƒ’áƒáƒ›áƒáƒ˜áƒ§áƒ”áƒœáƒ”áƒ‘áƒ¡ áƒáƒ› áƒ áƒ”áƒ’áƒ˜áƒ¡áƒ¢áƒ áƒ˜áƒ áƒ”áƒ‘áƒ£áƒš áƒ›áƒáƒ“áƒ”áƒšáƒ¡.\n",
        "\n",
        "# áƒ“áƒáƒ áƒ¬áƒ›áƒ£áƒœáƒ“áƒ˜áƒ—, áƒ áƒáƒ› training_run áƒáƒ¥áƒ¢áƒ˜áƒ£áƒ áƒ˜áƒ áƒáƒœ áƒ’áƒáƒ›áƒáƒ˜áƒ§áƒ”áƒœáƒ”áƒ— run_id training_run-áƒ“áƒáƒœ\n",
        "# áƒ—áƒ£ áƒ’áƒ¡áƒ£áƒ áƒ— áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ áƒ”áƒ’áƒ˜áƒ¡áƒ¢áƒ áƒáƒªáƒ˜áƒ áƒªáƒáƒšáƒ™áƒ” run-áƒ¨áƒ˜, áƒ¨áƒ”áƒ¥áƒ›áƒ”áƒœáƒ˜áƒ— áƒáƒ®áƒáƒšáƒ˜ run.\n",
        "# áƒáƒ› áƒ›áƒáƒ’áƒáƒšáƒ˜áƒ—áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡, áƒ•áƒ áƒ”áƒ’áƒ˜áƒ¡áƒ¢áƒ áƒ˜áƒ áƒ”áƒ‘áƒ— áƒ›áƒáƒ“áƒ”áƒšáƒ¡, áƒ áƒáƒ›áƒ”áƒšáƒ˜áƒª áƒáƒ®áƒšáƒáƒ®áƒáƒœ áƒ“áƒáƒ•áƒáƒ¢áƒ áƒ”áƒœáƒ˜áƒœáƒ’áƒ”áƒ—.\n",
        "\n",
        "# MLflow-áƒ¨áƒ˜ áƒ¨áƒ”áƒœáƒáƒ®áƒ£áƒšáƒ˜ áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ©áƒáƒ¢áƒ•áƒ˜áƒ áƒ—áƒ•áƒ MLflow-áƒ˜áƒ¡ Artifacts-áƒ“áƒáƒœ\n",
        "# áƒ áƒáƒ“áƒ’áƒáƒœ Prophet áƒáƒ  áƒáƒ áƒ˜áƒ¡ áƒáƒ˜áƒ áƒ“áƒáƒáƒ˜áƒ  PyTorch/Sklearn, áƒ©áƒ•áƒ”áƒœ áƒ˜áƒ¡ áƒ¨áƒ”áƒ•áƒ˜áƒœáƒáƒ®áƒ”áƒ— áƒ áƒáƒ’áƒáƒ áƒª pyfunc\n",
        "# áƒ“áƒ áƒáƒ®áƒšáƒ áƒ£áƒœáƒ“áƒ áƒ©áƒáƒ•áƒ¢áƒ•áƒ˜áƒ áƒ—áƒáƒ— áƒ¨áƒ”áƒ¡áƒáƒ‘áƒáƒ›áƒ˜áƒ¡áƒáƒ“.\n",
        "# áƒ”áƒ¡ áƒœáƒáƒ¬áƒ˜áƒšáƒ˜ áƒ¨áƒ”áƒ˜áƒ«áƒšáƒ”áƒ‘áƒ áƒ˜áƒ§áƒáƒ¡ model_inference.ipynb-áƒ¨áƒ˜áƒª.\n",
        "\n",
        "# áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ áƒ”áƒ’áƒ˜áƒ¡áƒ¢áƒ áƒáƒªáƒ˜áƒ\n",
        "# áƒ áƒ”áƒ’áƒ˜áƒ¡áƒ¢áƒ áƒáƒªáƒ˜áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡ áƒ¡áƒáƒ­áƒ˜áƒ áƒáƒ run_id, áƒ¡áƒáƒ˜áƒ“áƒáƒœáƒáƒª áƒ›áƒáƒ“áƒ”áƒšáƒ˜ áƒ“áƒáƒ˜áƒšáƒáƒ’áƒ.\n",
        "# training_run.info.run_id áƒáƒ áƒ˜áƒ¡ run_id training_run-áƒ˜áƒ¡áƒ—áƒ•áƒ˜áƒ¡.\n",
        "try:\n",
        "    registered_model = mlflow.register_model(\n",
        "        model_uri=f\"runs:/{training_run.info.run_id}/prophet_model\",\n",
        "        name=\"WalmartSalesProphetModel\"\n",
        "    )\n",
        "    print(f\"áƒ›áƒáƒ“áƒ”áƒšáƒ˜ 'WalmartSalesProphetModel' áƒ¬áƒáƒ áƒ›áƒáƒ¢áƒ”áƒ‘áƒ˜áƒ— áƒ“áƒáƒ áƒ”áƒ’áƒ˜áƒ¡áƒ¢áƒ áƒ˜áƒ áƒ“áƒ Model Registry-áƒ¨áƒ˜.\")\n",
        "    print(f\"áƒ•áƒ”áƒ áƒ¡áƒ˜áƒ: {registered_model.version}\")\n",
        "except Exception as e:\n",
        "    print(f\"áƒ¨áƒ”áƒªáƒ“áƒáƒ›áƒ áƒ›áƒáƒ“áƒ”áƒšáƒ˜áƒ¡ áƒ áƒ”áƒ’áƒ˜áƒ¡áƒ¢áƒ áƒáƒªáƒ˜áƒ˜áƒ¡áƒáƒ¡: {e}\")\n",
        "    print(\"áƒ“áƒáƒ áƒ¬áƒ›áƒ£áƒœáƒ“áƒ˜áƒ—, áƒ áƒáƒ› MLflow Tracking Server áƒ’áƒáƒ¨áƒ•áƒ”áƒ‘áƒ£áƒšáƒ˜áƒ áƒ“áƒ áƒ’áƒáƒ¥áƒ•áƒ— áƒ¬áƒ•áƒ“áƒáƒ›áƒ Model Registry-áƒ–áƒ”.\")"
      ],
      "metadata": {
        "id": "rNeLsfeQiQ2k"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9ca35ad8a798492186fa18149b612d57": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_d88cd209fd6e473fb61429496d14899b",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[32mâ ™\u001b[0m Waiting for authorization\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">â ™</span> Waiting for authorization\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "d88cd209fd6e473fb61429496d14899b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}