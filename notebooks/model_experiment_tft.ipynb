{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekvirika/WalmartRecruiting/blob/main/notebooks/model_experiment_tft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "08129789",
      "metadata": {
        "id": "08129789",
        "outputId": "9c6bfa4f-4c89-4a6a-eb15-6d9b6ce66345",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "0f0a10fe",
      "metadata": {
        "id": "0f0a10fe",
        "outputId": "025e8072-3fbf-4ab7-e1b8-f8c3ebd7cae5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/261.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.0/261.0 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q wandb torch torchvision pandas numpy matplotlib seaborn scikit-learn mlflow pytorch_lightning pytorch_forecasting mlflow\n",
        "\n",
        "# Set up Kaggle API\n",
        "!pip install -q kaggle pytorch_forecasting pytorch_lightning dagshub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "03d80336",
      "metadata": {
        "id": "03d80336"
      },
      "outputs": [],
      "source": [
        "# Upload your kaggle.json to Colab and run:\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/ColabNotebooks/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7173af2a",
      "metadata": {
        "id": "7173af2a",
        "outputId": "40ff2f17-36b9-4755-c49f-f2ef9551b182",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "walmart-recruiting-store-sales-forecasting.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "replace features.csv.zip? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ],
      "source": [
        "# Download the dataset\n",
        "!kaggle competitions download -c walmart-recruiting-store-sales-forecasting\n",
        "!unzip -q walmart-recruiting-store-sales-forecasting.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "17d2db62",
      "metadata": {
        "id": "17d2db62",
        "outputId": "dd072c20-5e16-48fc-df9b-234bb07a329f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "unzip:  cannot find or open stores.csv.zip, stores.csv.zip.zip or stores.csv.zip.ZIP.\n",
            "replace test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "replace features.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ],
      "source": [
        "!unzip -q train.csv.zip\n",
        "!unzip -q stores.csv.zip\n",
        "!unzip -q test.csv.zip\n",
        "!unzip -q features.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "40b2609c",
      "metadata": {
        "id": "40b2609c"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Deep Learning Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from pytorch_lightning.loggers import MLFlowLogger\n",
        "\n",
        "# Time Series Libraries\n",
        "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
        "from pytorch_forecasting.data import GroupNormalizer\n",
        "from pytorch_forecasting.metrics import SMAPE, MAE, RMSE\n",
        "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
        "\n",
        "# MLflow for experiment tracking\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "import mlflow.sklearn\n",
        "from mlflow.models.signature import infer_signature\n",
        "import joblib\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "74e4035c",
      "metadata": {
        "id": "74e4035c",
        "outputId": "d33f8b29-b9d1-4a57-e6f2-1f78ef80be75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "pl.seed_everything(42)\n",
        "\n",
        "print(\"All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2a37ab68",
      "metadata": {
        "id": "2a37ab68",
        "outputId": "67abf22a-d465-4668-a49c-9f163ddd4b67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/07/07 19:11:35 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
            "2025/07/07 19:11:35 INFO mlflow.store.db.utils: Updating database tables\n",
            "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
            "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
            "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
            "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLflow experiment 'TFT_Training' is ready!\n"
          ]
        }
      ],
      "source": [
        "# MLflow Experiment Setup\n",
        "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
        "experiment_name = \"TFT_Training\"\n",
        "mlflow.set_experiment(experiment_name)\n",
        "\n",
        "print(f\"MLflow experiment '{experiment_name}' is ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2a57ad43",
      "metadata": {
        "id": "2a57ad43"
      },
      "outputs": [],
      "source": [
        "# Data Loading and Initial Exploration\n",
        "def load_data():\n",
        "    \"\"\"Load and explore the Walmart dataset\"\"\"\n",
        "    train_df = pd.read_csv('train.csv')\n",
        "    test_df = pd.read_csv('test.csv')\n",
        "    stores_df = pd.read_csv('stores.csv')\n",
        "    features_df = pd.read_csv('features.csv')\n",
        "\n",
        "    print(\"Dataset shapes:\")\n",
        "    print(f\"Train: {train_df.shape}\")\n",
        "    print(f\"Test: {test_df.shape}\")\n",
        "    print(f\"Stores: {stores_df.shape}\")\n",
        "    print(f\"Features: {features_df.shape}\")\n",
        "\n",
        "    return train_df, test_df, stores_df, features_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "794c698b",
      "metadata": {
        "id": "794c698b"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "81b62c42",
      "metadata": {
        "id": "81b62c42",
        "outputId": "df4b94d1-4484-429f-8ebf-6e75b4a06bcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shapes:\n",
            "Train: (421570, 5)\n",
            "Test: (115064, 4)\n",
            "Stores: (45, 3)\n",
            "Features: (8190, 12)\n",
            "\n",
            "Train dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 421570 entries, 0 to 421569\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count   Dtype  \n",
            "---  ------        --------------   -----  \n",
            " 0   Store         421570 non-null  int64  \n",
            " 1   Dept          421570 non-null  int64  \n",
            " 2   Date          421570 non-null  object \n",
            " 3   Weekly_Sales  421570 non-null  float64\n",
            " 4   IsHoliday     421570 non-null  bool   \n",
            "dtypes: bool(1), float64(1), int64(2), object(1)\n",
            "memory usage: 13.3+ MB\n",
            "None\n",
            "\n",
            "Train dataset head:\n",
            "   Store  Dept        Date  Weekly_Sales  IsHoliday\n",
            "0      1     1  2010-02-05      24924.50      False\n",
            "1      1     1  2010-02-12      46039.49       True\n",
            "2      1     1  2010-02-19      41595.55      False\n",
            "3      1     1  2010-02-26      19403.54      False\n",
            "4      1     1  2010-03-05      21827.90      False\n",
            "\n",
            "Test dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 115064 entries, 0 to 115063\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count   Dtype \n",
            "---  ------     --------------   ----- \n",
            " 0   Store      115064 non-null  int64 \n",
            " 1   Dept       115064 non-null  int64 \n",
            " 2   Date       115064 non-null  object\n",
            " 3   IsHoliday  115064 non-null  bool  \n",
            "dtypes: bool(1), int64(2), object(1)\n",
            "memory usage: 2.7+ MB\n",
            "None\n",
            "\n",
            "Test dataset head:\n",
            "   Store  Dept        Date  IsHoliday\n",
            "0      1     1  2012-11-02      False\n",
            "1      1     1  2012-11-09      False\n",
            "2      1     1  2012-11-16      False\n",
            "3      1     1  2012-11-23       True\n",
            "4      1     1  2012-11-30      False\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "train_df, test_df, stores_df, features_df = load_data()\n",
        "# Display basic info about the datasets\n",
        "print(\"\\nTrain dataset info:\")\n",
        "print(train_df.info())\n",
        "print(f\"\\nTrain dataset head:\\n{train_df.head()}\")\n",
        "\n",
        "print(\"\\nTest dataset info:\")\n",
        "print(test_df.info())\n",
        "print(f\"\\nTest dataset head:\\n{test_df.head()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3dae799",
      "metadata": {
        "id": "e3dae799"
      },
      "source": [
        "# MLflow Run: Data Cleaning and Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "feede334",
      "metadata": {
        "id": "feede334",
        "outputId": "6f8a4c4b-8883-41ae-adde-1444775ae5ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting data cleaning and preprocessing...\n",
            "Missing values before cleaning: 0\n",
            "Missing values after cleaning: 0\n",
            "Missing values before cleaning: 0\n",
            "Missing values after cleaning: 0\n",
            "Data cleaning completed!\n"
          ]
        }
      ],
      "source": [
        "with mlflow.start_run(run_name=\"TFT_Data_Cleaning\"):\n",
        "    print(\"Starting data cleaning and preprocessing...\")\n",
        "\n",
        "    # Log parameters\n",
        "    mlflow.log_param(\"train_shape\", train_df.shape)\n",
        "    mlflow.log_param(\"test_shape\", test_df.shape)\n",
        "\n",
        "    # Data cleaning function\n",
        "    def clean_data(df):\n",
        "        \"\"\"Clean the dataset\"\"\"\n",
        "        # Convert Date to datetime\n",
        "        df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "        # Handle missing values\n",
        "        missing_before = df.isnull().sum().sum()\n",
        "\n",
        "        # Fill missing values with appropriate methods\n",
        "        if 'Weekly_Sales' in df.columns:\n",
        "            # For training data\n",
        "            df['Weekly_Sales'].fillna(df['Weekly_Sales'].median(), inplace=True)\n",
        "\n",
        "        missing_after = df.isnull().sum().sum()\n",
        "\n",
        "        print(f\"Missing values before cleaning: {missing_before}\")\n",
        "        print(f\"Missing values after cleaning: {missing_after}\")\n",
        "\n",
        "        return df, missing_before, missing_after\n",
        "\n",
        "    # Clean training data\n",
        "    train_df, missing_before_train, missing_after_train = clean_data(train_df)\n",
        "\n",
        "    # Clean test data\n",
        "    test_df, missing_before_test, missing_after_test = clean_data(test_df)\n",
        "\n",
        "    # Log cleaning metrics\n",
        "    mlflow.log_metric(\"missing_before_train\", missing_before_train)\n",
        "    mlflow.log_metric(\"missing_after_train\", missing_after_train)\n",
        "    mlflow.log_metric(\"missing_before_test\", missing_before_test)\n",
        "    mlflow.log_metric(\"missing_after_test\", missing_after_test)\n",
        "\n",
        "    print(\"Data cleaning completed!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca7761ab",
      "metadata": {
        "id": "ca7761ab"
      },
      "source": [
        "# Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "35494272",
      "metadata": {
        "id": "35494272",
        "outputId": "bf8b39da-b195-4925-e14f-f35dfbf36b18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting feature engineering...\n",
            "Available columns:\n",
            "  train_df: ['Store', 'Dept', 'Date', 'Weekly_Sales', 'IsHoliday', 'Year', 'Month', 'Week', 'Day', 'DayOfWeek', 'Quarter']\n",
            "  stores_df: ['Store', 'Type', 'Size']\n",
            "  features_df: ['Store', 'Date', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment']\n",
            "Overlapping columns with stores_df: []\n",
            "Feature engineering completed!\n",
            "Train shape: (421570, 23)\n",
            "Test shape: (115064, 22)\n",
            "Train columns: ['Store', 'Dept', 'Date', 'Weekly_Sales', 'IsHoliday', 'Year', 'Month', 'Week', 'Day', 'DayOfWeek', 'Quarter', 'Type', 'Size', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'Type_encoded']\n",
            "Test columns: ['Store', 'Dept', 'Date', 'IsHoliday', 'Year', 'Month', 'Week', 'Day', 'DayOfWeek', 'Quarter', 'Type', 'Size', 'Temperature', 'Fuel_Price', 'MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5', 'CPI', 'Unemployment', 'Type_encoded']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mlflow\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "with mlflow.start_run(run_name=\"TFT_Feature_Engineering\"):\n",
        "    print(\"Starting feature engineering...\")\n",
        "\n",
        "    # --- Ensure Date columns are datetime ---\n",
        "    train_df['Date'] = pd.to_datetime(train_df['Date'])\n",
        "    test_df['Date'] = pd.to_datetime(test_df['Date'])\n",
        "    features_df['Date'] = pd.to_datetime(features_df['Date'])\n",
        "    stores_df = stores_df.copy()  # in case you want to modify safely\n",
        "\n",
        "    features_df = features_df.drop(columns=['IsHoliday'], errors='ignore')\n",
        "\n",
        "    # --- Feature engineering function ---\n",
        "    def engineer_features(df):\n",
        "        df['Year'] = df['Date'].dt.year\n",
        "        df['Month'] = df['Date'].dt.month\n",
        "        df['Week'] = df['Date'].dt.isocalendar().week\n",
        "        df['Day'] = df['Date'].dt.day\n",
        "        df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
        "        df['Quarter'] = df['Date'].dt.quarter\n",
        "        df['IsHoliday'] = df['IsHoliday'].astype(int)\n",
        "        df = df.sort_values(['Store', 'Date']).reset_index(drop=True)\n",
        "        return df\n",
        "\n",
        "    # --- Apply feature engineering ---\n",
        "    train_df = engineer_features(train_df)\n",
        "    test_df = engineer_features(test_df)\n",
        "\n",
        "    # --- Handle overlapping columns more carefully ---\n",
        "    # First, identify what columns exist in each dataframe\n",
        "    print(\"Available columns:\")\n",
        "    print(f\"  train_df: {list(train_df.columns)}\")\n",
        "    print(f\"  stores_df: {list(stores_df.columns)}\")\n",
        "    print(f\"  features_df: {list(features_df.columns)}\")\n",
        "\n",
        "    # Check what columns overlap between train_df and stores_df\n",
        "    stores_overlap = [col for col in stores_df.columns if col in train_df.columns and col != 'Store']\n",
        "    print(f\"Overlapping columns with stores_df: {stores_overlap}\")\n",
        "\n",
        "    # Only drop columns that actually exist in both and cause conflicts\n",
        "    # Keep Type and Size from stores_df by dropping them from train_df if they exist\n",
        "    if 'Type' in train_df.columns and 'Type' in stores_df.columns:\n",
        "        train_df = train_df.drop(columns=['Type'], errors='ignore')\n",
        "        test_df = test_df.drop(columns=['Type'], errors='ignore')\n",
        "    if 'Size' in train_df.columns and 'Size' in stores_df.columns:\n",
        "        train_df = train_df.drop(columns=['Size'], errors='ignore')\n",
        "        test_df = test_df.drop(columns=['Size'], errors='ignore')\n",
        "\n",
        "    # --- Merge with stores data ---\n",
        "    train_df = train_df.merge(stores_df, on='Store', how='left')\n",
        "    test_df = test_df.merge(stores_df, on='Store', how='left')\n",
        "\n",
        "    # Check for overlapping columns with features_df and drop them from train/test\n",
        "    features_overlap = [col for col in features_df.columns if col in train_df.columns and col not in ['Store', 'Date']]\n",
        "    if features_overlap:\n",
        "        print(f\"Dropping overlapping columns before features merge: {features_overlap}\")\n",
        "        train_df = train_df.drop(columns=features_overlap, errors='ignore')\n",
        "        test_df = test_df.drop(columns=features_overlap, errors='ignore')\n",
        "\n",
        "    # --- Merge with features data ---\n",
        "    train_df = train_df.merge(features_df, on=['Store', 'Date'], how='left')\n",
        "    test_df = test_df.merge(features_df, on=['Store', 'Date'], how='left')\n",
        "\n",
        "    # --- Encode categorical variables ---\n",
        "    # Check if Type column exists before encoding\n",
        "    if 'Type' in train_df.columns:\n",
        "        le_type = LabelEncoder()\n",
        "        train_df['Type_encoded'] = le_type.fit_transform(train_df['Type'])\n",
        "        test_df['Type_encoded'] = le_type.transform(test_df['Type'])\n",
        "    else:\n",
        "        print(\"Warning: 'Type' column not found in dataframes after merging\")\n",
        "\n",
        "    # --- Fill missing values in numerical columns (handle train and test separately) ---\n",
        "    # Get numeric columns for each dataset separately\n",
        "    train_numeric_cols = train_df.select_dtypes(include=[np.number]).columns\n",
        "    test_numeric_cols = test_df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "    # Fill missing values using medians from training data\n",
        "    train_df[train_numeric_cols] = train_df[train_numeric_cols].fillna(train_df[train_numeric_cols].median())\n",
        "\n",
        "    # For test data, use training data medians for common columns, test data medians for test-only columns\n",
        "    for col in test_numeric_cols:\n",
        "        if col in train_numeric_cols:\n",
        "            # Use training data median for consistency\n",
        "            test_df[col] = test_df[col].fillna(train_df[col].median())\n",
        "        else:\n",
        "            # Use test data median for columns not in training data\n",
        "            test_df[col] = test_df[col].fillna(test_df[col].median())\n",
        "\n",
        "    # --- Log to MLflow ---\n",
        "    mlflow.log_param(\"features_after_engineering\", len(train_df.columns))\n",
        "    mlflow.log_param(\"time_features_added\", 6)\n",
        "    mlflow.log_param(\"train_numeric_cols\", len(train_numeric_cols))\n",
        "    mlflow.log_param(\"test_numeric_cols\", len(test_numeric_cols))\n",
        "\n",
        "    print(f\"Feature engineering completed!\")\n",
        "    print(f\"Train shape: {train_df.shape}\")\n",
        "    print(f\"Test shape: {test_df.shape}\")\n",
        "    print(f\"Train columns: {list(train_df.columns)}\")\n",
        "    print(f\"Test columns: {list(test_df.columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d594729e",
      "metadata": {
        "id": "d594729e",
        "outputId": "2fcd9583-d734-4951-d040-b0f86fb253e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing data for TFT...\n",
            "Training data shape: (415661, 24)\n",
            "Validation data shape: (5909, 24)\n",
            "Data preparation completed!\n"
          ]
        }
      ],
      "source": [
        "# Prepare data for TFT\n",
        "with mlflow.start_run(run_name=\"TFT_Data_Preparation\"):\n",
        "    print(\"Preparing data for TFT...\")\n",
        "\n",
        "    # Create time index\n",
        "    train_df['time_idx'] = (train_df['Date'] - train_df['Date'].min()).dt.days\n",
        "    test_df['time_idx'] = (test_df['Date'] - train_df['Date'].min()).dt.days\n",
        "\n",
        "    # Define the features for TFT\n",
        "    static_categoricals = ['Store', 'Type_encoded']\n",
        "    static_reals = ['Size']\n",
        "    time_varying_known_categoricals = ['IsHoliday', 'Month', 'Quarter', 'DayOfWeek']\n",
        "    time_varying_known_reals = ['time_idx']\n",
        "    time_varying_unknown_reals = ['Weekly_Sales']\n",
        "\n",
        "    # Add external features if available\n",
        "    external_features = ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
        "    available_external = [col for col in external_features if col in train_df.columns]\n",
        "    time_varying_known_reals.extend(available_external)\n",
        "\n",
        "    # Create target variable\n",
        "    target = 'Weekly_Sales'\n",
        "\n",
        "    # Split data for validation\n",
        "    max_prediction_length = 12  # 12 weeks ahead\n",
        "    max_encoder_length = 52     # Use 52 weeks of history\n",
        "\n",
        "    # Calculate cutoff for validation\n",
        "    cutoff = train_df['time_idx'].max() - max_prediction_length\n",
        "\n",
        "    # Create training and validation sets\n",
        "    training_data = train_df[train_df['time_idx'] <= cutoff]\n",
        "    validation_data = train_df[train_df['time_idx'] > cutoff]\n",
        "\n",
        "    print(f\"Training data shape: {training_data.shape}\")\n",
        "    print(f\"Validation data shape: {validation_data.shape}\")\n",
        "\n",
        "    # Log data preparation parameters\n",
        "    mlflow.log_param(\"max_prediction_length\", max_prediction_length)\n",
        "    mlflow.log_param(\"max_encoder_length\", max_encoder_length)\n",
        "    mlflow.log_param(\"training_samples\", len(training_data))\n",
        "    mlflow.log_param(\"validation_samples\", len(validation_data))\n",
        "\n",
        "    print(\"Data preparation completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47bcc5e6",
      "metadata": {
        "id": "47bcc5e6"
      },
      "source": [
        "# Create TFT Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ac2d88cd",
      "metadata": {
        "id": "ac2d88cd",
        "outputId": "dfadc421-a853-41c8-c6df-f20cb4cdb3fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating TFT dataset...\n",
            "Missing values in Weekly_Sales before handling: 0\n",
            "Missing values in Weekly_Sales after handling: 0\n",
            "Final check - NaN: 0, Inf: 0\n",
            "Training subset shape: (415661, 24)\n",
            "Missing values in Weekly_Sales in training subset: 0\n",
            "Final training subset check - NaN: 0, Inf: 0\n",
            "Checking all columns for missing values:\n",
            "Filling any remaining missing values in all columns...\n",
            "Final check of all columns after comprehensive cleaning:\n",
            "Total missing values across all columns: 0\n",
            "Weekly_Sales statistics:\n",
            "  Min: -4988.94\n",
            "  Max: 693099.36\n",
            "  Mean: 15990.320141293021\n",
            "  Unique values with potential issues: 1347\n",
            "Found non-positive values in Weekly_Sales, adjusting for GroupNormalizer...\n",
            "Training dataset size: 798711\n",
            "Validation dataset size: 45\n",
            "Dataset creation completed!\n"
          ]
        }
      ],
      "source": [
        "with mlflow.start_run(run_name=\"TFT_Dataset_Creation\"):\n",
        "    print(\"Creating TFT dataset...\")\n",
        "\n",
        "    # Convert Store to string type for categorical handling\n",
        "    train_df['Store'] = train_df['Store'].astype(str)\n",
        "\n",
        "    # Also convert any other categorical columns that might be numeric\n",
        "    for col in static_categoricals + time_varying_known_categoricals:\n",
        "        if col in train_df.columns:\n",
        "            train_df[col] = train_df[col].astype(str)\n",
        "\n",
        "    # Handle missing values in target variable\n",
        "    print(f\"Missing values in {target} before handling: {train_df[target].isna().sum()}\")\n",
        "\n",
        "    # Option 1: Fill missing target values with forward fill then backward fill\n",
        "    train_df[target] = train_df.groupby('Store')[target].fillna(method='ffill').fillna(method='bfill')\n",
        "\n",
        "    # Option 2: If still missing, fill with store-specific median\n",
        "    train_df[target] = train_df.groupby('Store')[target].fillna(train_df.groupby('Store')[target].transform('median'))\n",
        "\n",
        "    # Option 3: If still missing, fill with overall median\n",
        "    train_df[target] = train_df[target].fillna(train_df[target].median())\n",
        "\n",
        "    print(f\"Missing values in {target} after handling: {train_df[target].isna().sum()}\")\n",
        "\n",
        "    # Check for infinite values and handle them\n",
        "    inf_mask = np.isinf(train_df[target])\n",
        "    if inf_mask.any():\n",
        "        print(f\"Found {inf_mask.sum()} infinite values in {target}, replacing with median\")\n",
        "        train_df.loc[inf_mask, target] = train_df[target].median()\n",
        "\n",
        "    # Final check for any remaining problematic values\n",
        "    print(f\"Final check - NaN: {train_df[target].isna().sum()}, Inf: {np.isinf(train_df[target]).sum()}\")\n",
        "\n",
        "    # Create the filtered dataset for training\n",
        "    train_subset = train_df[train_df['time_idx'] <= cutoff].copy()\n",
        "    print(f\"Training subset shape: {train_subset.shape}\")\n",
        "    print(f\"Missing values in {target} in training subset: {train_subset[target].isna().sum()}\")\n",
        "\n",
        "    # Handle missing values in the training subset\n",
        "    if train_subset[target].isna().sum() > 0:\n",
        "        print(\"Handling missing values in training subset...\")\n",
        "        # Fill missing values in the training subset\n",
        "        train_subset[target] = train_subset.groupby('Store')[target].fillna(method='ffill').fillna(method='bfill')\n",
        "        train_subset[target] = train_subset.groupby('Store')[target].fillna(train_subset.groupby('Store')[target].transform('median'))\n",
        "        train_subset[target] = train_subset[target].fillna(train_subset[target].median())\n",
        "\n",
        "        # Handle infinite values\n",
        "        inf_mask = np.isinf(train_subset[target])\n",
        "        if inf_mask.any():\n",
        "            print(f\"Found {inf_mask.sum()} infinite values in training subset, replacing with median\")\n",
        "            train_subset.loc[inf_mask, target] = train_subset[target].median()\n",
        "\n",
        "    print(f\"Final training subset check - NaN: {train_subset[target].isna().sum()}, Inf: {np.isinf(train_subset[target]).sum()}\")\n",
        "\n",
        "    # Additional debugging - check all columns for missing values\n",
        "    print(\"Checking all columns for missing values:\")\n",
        "    for col in train_subset.columns:\n",
        "        missing_count = train_subset[col].isna().sum()\n",
        "        if missing_count > 0:\n",
        "            print(f\"  {col}: {missing_count} missing values\")\n",
        "\n",
        "    # Check for any problematic values in all numeric columns\n",
        "    numeric_cols = train_subset.select_dtypes(include=[np.number]).columns\n",
        "    for col in numeric_cols:\n",
        "        inf_count = np.isinf(train_subset[col]).sum()\n",
        "        if inf_count > 0:\n",
        "            print(f\"  {col}: {inf_count} infinite values\")\n",
        "            train_subset[col] = train_subset[col].replace([np.inf, -np.inf], train_subset[col].median())\n",
        "\n",
        "    # Fill any remaining missing values in all columns\n",
        "    print(\"Filling any remaining missing values in all columns...\")\n",
        "    for col in train_subset.columns:\n",
        "        if train_subset[col].isna().sum() > 0:\n",
        "            if train_subset[col].dtype == 'object':\n",
        "                # For categorical columns, fill with mode\n",
        "                train_subset[col] = train_subset[col].fillna(train_subset[col].mode()[0] if len(train_subset[col].mode()) > 0 else 'Unknown')\n",
        "            else:\n",
        "                # For numeric columns, fill with median\n",
        "                train_subset[col] = train_subset[col].fillna(train_subset[col].median())\n",
        "\n",
        "    print(\"Final check of all columns after comprehensive cleaning:\")\n",
        "    total_missing = train_subset.isna().sum().sum()\n",
        "    print(f\"Total missing values across all columns: {total_missing}\")\n",
        "\n",
        "    # Debug: Check the actual values in Weekly_Sales\n",
        "    print(f\"Weekly_Sales statistics:\")\n",
        "    print(f\"  Min: {train_subset[target].min()}\")\n",
        "    print(f\"  Max: {train_subset[target].max()}\")\n",
        "    print(f\"  Mean: {train_subset[target].mean()}\")\n",
        "    print(f\"  Unique values with potential issues: {train_subset[target][train_subset[target] <= 0].count()}\")\n",
        "\n",
        "    # Handle edge cases that might cause issues with GroupNormalizer\n",
        "    if (train_subset[target] <= 0).any():\n",
        "        print(\"Found non-positive values in Weekly_Sales, adjusting for GroupNormalizer...\")\n",
        "        # Add a small constant to ensure all values are positive for softplus transformation\n",
        "        min_val = train_subset[target].min()\n",
        "        if min_val <= 0:\n",
        "            train_subset[target] = train_subset[target] + abs(min_val) + 1\n",
        "\n",
        "    # Try with a simpler normalizer first\n",
        "    from pytorch_forecasting.data.encoders import EncoderNormalizer\n",
        "\n",
        "    # Create the dataset with a simpler normalizer\n",
        "    training_dataset = TimeSeriesDataSet(\n",
        "        train_subset,\n",
        "        time_idx='time_idx',\n",
        "        target=target,\n",
        "        group_ids=['Store'],\n",
        "        min_encoder_length=max_encoder_length // 2,\n",
        "        max_encoder_length=max_encoder_length,\n",
        "        min_prediction_length=1,\n",
        "        max_prediction_length=max_prediction_length,\n",
        "        static_categoricals=static_categoricals,\n",
        "        static_reals=static_reals,\n",
        "        time_varying_known_categoricals=time_varying_known_categoricals,\n",
        "        time_varying_known_reals=time_varying_known_reals,\n",
        "        time_varying_unknown_reals=time_varying_unknown_reals,\n",
        "        target_normalizer=EncoderNormalizer(),  # Use simpler normalizer\n",
        "        add_relative_time_idx=True,\n",
        "        add_target_scales=True,\n",
        "        add_encoder_length=True,\n",
        "        allow_missing_timesteps=True,\n",
        "    )\n",
        "\n",
        "    # Create validation dataset\n",
        "    validation_dataset = TimeSeriesDataSet.from_dataset(\n",
        "        training_dataset,\n",
        "        train_df,\n",
        "        predict=True,\n",
        "        stop_randomization=True\n",
        "    )\n",
        "\n",
        "    # Create dataloaders\n",
        "    batch_size = 128\n",
        "    train_dataloader = training_dataset.to_dataloader(\n",
        "        train=True,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=0\n",
        "    )\n",
        "    val_dataloader = validation_dataset.to_dataloader(\n",
        "        train=False,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=0\n",
        "    )\n",
        "\n",
        "    print(f\"Training dataset size: {len(training_dataset)}\")\n",
        "    print(f\"Validation dataset size: {len(validation_dataset)}\")\n",
        "\n",
        "    # Log dataset parameters\n",
        "    mlflow.log_param(\"batch_size\", batch_size)\n",
        "    mlflow.log_param(\"train_dataset_size\", len(training_dataset))\n",
        "    mlflow.log_param(\"val_dataset_size\", len(validation_dataset))\n",
        "\n",
        "    print(\"Dataset creation completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff339cbd",
      "metadata": {
        "id": "ff339cbd"
      },
      "source": [
        "# Model Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "5606b68f",
      "metadata": {
        "id": "5606b68f",
        "outputId": "fa286910-a184-409f-fc3b-0a04d32edc72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "47ef9c4b680a4d59a31c2aa1fc471c4f",
            "5bb1858e6a9745d8acf9da6b7e80a294",
            "c5552a40448a4dd38e7af239c5bf7bb7",
            "fcdbfcac322048999d6d3473475ce099",
            "2515e0b01c7e40c482af3f3a5c74776b",
            "930ba19096ec4a94a265f60c23e50b4e",
            "ceb3c4965bba4c70bb4cd503a8ee5783",
            "2708ffabf1f646f1a0d7ea2b6b2b7b92",
            "68cfe7fd89984847b62996603b903427",
            "fbb0564f1ac6440d91cea6791f0412a9",
            "48fc91d26d1342b3ae329af1c0f5de0a",
            "b253803b7665473db6c82aa588b812ee",
            "9865654d818e4d0c9ced1cba9d35f5ac",
            "f3b5546c65004f3eb29b8ebf809c66a5",
            "d4623f9b992442bc81874937486c5600",
            "26c06d1545c6437e8bb0c6bb2301457a",
            "249ac93b637c49ecbde3a9ad1504a116",
            "7e996875396249b4b33948428c9cab2c",
            "f89cde0ab88645d4b434e8a06b8dfdbc",
            "94e784dfb9cc42769e6fd1e9782c4349",
            "c2fdae4d3ee6443a85b68d46772f6692",
            "6b14a3a86b264e3c86696559f0e70fd3"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting TFT model training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO  [lightning.pytorch.utilities.rank_zero] GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO  [lightning.pytorch.utilities.rank_zero] TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO  [lightning.pytorch.utilities.rank_zero] HPU available: False, using: 0 HPUs\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO  [lightning.pytorch.accelerators.cuda] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "   | Name                               | Type                            | Params | Mode \n",
            "------------------------------------------------------------------------------------------------\n",
            "0  | loss                               | SMAPE                           | 0      | train\n",
            "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
            "2  | input_embeddings                   | MultiEmbedding                  | 681    | train\n",
            "3  | prescalers                         | ModuleDict                      | 176    | train\n",
            "4  | static_variable_selection          | VariableSelectionNetwork        | 7.4 K  | train\n",
            "5  | encoder_variable_selection         | VariableSelectionNetwork        | 14.1 K | train\n",
            "6  | decoder_variable_selection         | VariableSelectionNetwork        | 12.2 K | train\n",
            "7  | static_context_variable_selection  | GatedResidualNetwork            | 16.8 K | train\n",
            "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 16.8 K | train\n",
            "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 16.8 K | train\n",
            "10 | static_context_enrichment          | GatedResidualNetwork            | 16.8 K | train\n",
            "11 | lstm_encoder                       | LSTM                            | 66.6 K | train\n",
            "12 | lstm_decoder                       | LSTM                            | 66.6 K | train\n",
            "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 8.3 K  | train\n",
            "14 | post_lstm_add_norm_encoder         | AddNorm                         | 128    | train\n",
            "15 | static_enrichment                  | GatedResidualNetwork            | 20.9 K | train\n",
            "16 | multihead_attn                     | InterpretableMultiHeadAttention | 10.4 K | train\n",
            "17 | post_attn_gate_norm                | GateAddNorm                     | 8.4 K  | train\n",
            "18 | pos_wise_ff                        | GatedResidualNetwork            | 16.8 K | train\n",
            "19 | pre_output_gate_norm               | GateAddNorm                     | 8.4 K  | train\n",
            "20 | output_layer                       | Linear                          | 65     | train\n",
            "------------------------------------------------------------------------------------------------\n",
            "307 K     Trainable params\n",
            "0         Non-trainable params\n",
            "307 K     Total params\n",
            "1.231     Total estimated model params size (MB)\n",
            "456       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO  [lightning.pytorch.callbacks.model_summary] \n",
            "   | Name                               | Type                            | Params | Mode \n",
            "------------------------------------------------------------------------------------------------\n",
            "0  | loss                               | SMAPE                           | 0      | train\n",
            "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
            "2  | input_embeddings                   | MultiEmbedding                  | 681    | train\n",
            "3  | prescalers                         | ModuleDict                      | 176    | train\n",
            "4  | static_variable_selection          | VariableSelectionNetwork        | 7.4 K  | train\n",
            "5  | encoder_variable_selection         | VariableSelectionNetwork        | 14.1 K | train\n",
            "6  | decoder_variable_selection         | VariableSelectionNetwork        | 12.2 K | train\n",
            "7  | static_context_variable_selection  | GatedResidualNetwork            | 16.8 K | train\n",
            "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 16.8 K | train\n",
            "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 16.8 K | train\n",
            "10 | static_context_enrichment          | GatedResidualNetwork            | 16.8 K | train\n",
            "11 | lstm_encoder                       | LSTM                            | 66.6 K | train\n",
            "12 | lstm_decoder                       | LSTM                            | 66.6 K | train\n",
            "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 8.3 K  | train\n",
            "14 | post_lstm_add_norm_encoder         | AddNorm                         | 128    | train\n",
            "15 | static_enrichment                  | GatedResidualNetwork            | 20.9 K | train\n",
            "16 | multihead_attn                     | InterpretableMultiHeadAttention | 10.4 K | train\n",
            "17 | post_attn_gate_norm                | GateAddNorm                     | 8.4 K  | train\n",
            "18 | pos_wise_ff                        | GatedResidualNetwork            | 16.8 K | train\n",
            "19 | pre_output_gate_norm               | GateAddNorm                     | 8.4 K  | train\n",
            "20 | output_layer                       | Linear                          | 65     | train\n",
            "------------------------------------------------------------------------------------------------\n",
            "307 K     Trainable params\n",
            "0         Non-trainable params\n",
            "307 K     Total params\n",
            "1.231     Total estimated model params size (MB)\n",
            "456       Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47ef9c4b680a4d59a31c2aa1fc471c4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b253803b7665473db6c82aa588b812ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "upsample_linear1d_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True)'. You can turn off determinism just for this operation, or you can use the 'warn_only=True' option, if that's acceptable for your application. You can also file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-54-1720517899.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     trainer.fit(\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mtft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/utils/autologging_utils/safety.py\u001b[0m in \u001b[0;36msafe_patch_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m                     \u001b[0mevent_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_patch_function_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                     \u001b[0mpatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_original\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"succeeded\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/utils/autologging_utils/safety.py\u001b[0m in \u001b[0;36mpatch_with_managed_run\u001b[0;34m(original, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;31m# In addition to standard Python exceptions, handle keyboard interrupts to ensure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/pytorch/_lightning_autolog.py\u001b[0m in \u001b[0;36mpatched_fit\u001b[0;34m(original, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mearly_stop_callback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/utils/autologging_utils/safety.py\u001b[0m in \u001b[0;36mcall_original\u001b[0;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m                                 \u001b[0;32mreturn\u001b[0m \u001b[0moriginal_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                         \u001b[0;32mreturn\u001b[0m \u001b[0mcall_original_fn_with_event_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_original_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mog_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mog_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                     \u001b[0;31m# Apply the name, docstring, and signature of `original` to `call_original`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/utils/autologging_utils/safety.py\u001b[0m in \u001b[0;36mcall_original_fn_with_event_logging\u001b[0;34m(original_fn, og_args, og_kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m                         \u001b[0mevent_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_original_function_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mog_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mog_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m                         \u001b[0moriginal_fn_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mog_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mog_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m                         \u001b[0mevent_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_original_function_success\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mog_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mog_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mlflow/utils/autologging_utils/safety.py\u001b[0m in \u001b[0;36m_original_fn\u001b[0;34m(*_og_args, **_og_kwargs)\u001b[0m\n\u001b[1;32m    470\u001b[0m                                 \u001b[0mreroute_warnings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                             ):\n\u001b[0;32m--> 472\u001b[0;31m                                 \u001b[0moriginal_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_og_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_og_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m                                 \u001b[0;32mreturn\u001b[0m \u001b[0moriginal_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    597\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         )\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1012\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1054\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unexpected state {self.state}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/fit_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m                     \u001b[0;31m# in automatic optimization, there can only be one optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                     \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautomatic_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                     \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/optimization/automatic.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;31m# gradient update with accumulated gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsume_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m_optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;31m# model hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         call._call_lightning_module_hook(\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;34m\"optimizer_step\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/call.py\u001b[0m in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LightningModule]{pl_module.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/module.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m         \"\"\"\n\u001b[0;32m-> 1328\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mstep_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_after_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/strategies/strategy.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;31m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_model_and_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/plugins/precision/precision.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;34m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mclosure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     def _clip_gradients(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m                             )\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/plugins/precision/precision.py\u001b[0m in \u001b[0;36m_wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \"\"\"\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mclosure_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclosure_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/optimization/automatic.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/optimization/automatic.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstep_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosure_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loops/optimization/automatic.py\u001b[0m in \u001b[0;36mbackward_fn\u001b[0;34m(loss)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mbackward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"backward\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbackward_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/trainer/call.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{trainer.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/strategies/strategy.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, closure_loss, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mclosure_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mclosure_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/plugins/precision/precision.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, tensor, model, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \"\"\"\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightning/pytorch/core/module.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fabric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoggle_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLightningOptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: upsample_linear1d_backward_out_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True)'. You can turn off determinism just for this operation, or you can use the 'warn_only=True' option, if that's acceptable for your application. You can also file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation."
          ]
        }
      ],
      "source": [
        "import lightning.pytorch as pl  # Fixed import\n",
        "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from lightning.pytorch.loggers import MLFlowLogger\n",
        "\n",
        "with mlflow.start_run(run_name=\"TFT_Model_Training\"):\n",
        "    print(\"Starting TFT model training...\")\n",
        "\n",
        "    # Enable MLflow auto-logging for PyTorch Lightning\n",
        "    mlflow.pytorch.autolog()\n",
        "\n",
        "    # Create MLflow logger\n",
        "    mlflow_logger = MLFlowLogger(\n",
        "        experiment_name=experiment_name,\n",
        "        tracking_uri=mlflow.get_tracking_uri()\n",
        "    )\n",
        "\n",
        "    # Model configuration\n",
        "    model_config = {\n",
        "        \"hidden_size\": 64,\n",
        "        \"lstm_layers\": 2,\n",
        "        \"dropout\": 0.1,\n",
        "        \"attention_head_size\": 4,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"reduce_on_plateau_patience\": 3,\n",
        "        \"optimizer\": \"Adam\"\n",
        "    }\n",
        "\n",
        "    # Create the model\n",
        "    tft = TemporalFusionTransformer.from_dataset(\n",
        "        training_dataset,\n",
        "        hidden_size=model_config[\"hidden_size\"],\n",
        "        lstm_layers=model_config[\"lstm_layers\"],\n",
        "        dropout=model_config[\"dropout\"],\n",
        "        attention_head_size=model_config[\"attention_head_size\"],\n",
        "        output_size=1,  # Fixed for SMAPE loss\n",
        "        loss=SMAPE(),\n",
        "        learning_rate=model_config[\"learning_rate\"],\n",
        "        reduce_on_plateau_patience=model_config[\"reduce_on_plateau_patience\"],\n",
        "        optimizer=model_config[\"optimizer\"],\n",
        "    )\n",
        "\n",
        "    # Log model configuration\n",
        "    for key, value in model_config.items():\n",
        "        mlflow.log_param(key, value)\n",
        "\n",
        "    # Setup callbacks\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=10,\n",
        "        verbose=True,\n",
        "        mode='min'\n",
        "    )\n",
        "\n",
        "    checkpoint_callback = ModelCheckpoint(\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "        save_top_k=1,\n",
        "        filename='best_tft_model'\n",
        "    )\n",
        "\n",
        "    # Create trainer - FIXED: Removed deterministic=True\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=50,\n",
        "        accelerator='gpu',\n",
        "        devices=1,\n",
        "        callbacks=[early_stopping, checkpoint_callback],\n",
        "        logger=mlflow_logger,\n",
        "        enable_progress_bar=True,\n",
        "        # Removed: deterministic=True\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.fit(\n",
        "        tft,\n",
        "        train_dataloaders=train_dataloader,\n",
        "        val_dataloaders=val_dataloader\n",
        "    )\n",
        "\n",
        "    # Load best model\n",
        "    best_model = TemporalFusionTransformer.load_from_checkpoint(\n",
        "        checkpoint_callback.best_model_path\n",
        "    )\n",
        "\n",
        "    print(\"Model training completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model type: {type(tft)}\")\n",
        "print(f\"Is LightningModule: {isinstance(tft, pl.LightningModule)}\")\n",
        "print(f\"Model MRO: {type(tft).__mro__}\")"
      ],
      "metadata": {
        "id": "QM_yRHTQciMk",
        "outputId": "b3066107-7ede-4f55-ef80-ccce76d9c987",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QM_yRHTQciMk",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model type: <class 'pytorch_forecasting.models.temporal_fusion_transformer._tft.TemporalFusionTransformer'>\n",
            "Is LightningModule: False\n",
            "Model MRO: (<class 'pytorch_forecasting.models.temporal_fusion_transformer._tft.TemporalFusionTransformer'>, <class 'pytorch_forecasting.models.base._base_model.BaseModelWithCovariates'>, <class 'pytorch_forecasting.models.base._base_model.BaseModel'>, <class 'pytorch_forecasting.utils._utils.InitialParameterRepresenterMixIn'>, <class 'lightning.pytorch.core.module.LightningModule'>, <class 'lightning.fabric.utilities.device_dtype_mixin._DeviceDtypeModuleMixin'>, <class 'lightning.pytorch.core.mixins.hparams_mixin.HyperparametersMixin'>, <class 'lightning.pytorch.core.hooks.ModelHooks'>, <class 'lightning.pytorch.core.hooks.DataHooks'>, <class 'lightning.pytorch.core.hooks.CheckpointHooks'>, <class 'torch.nn.modules.module.Module'>, <class 'pytorch_forecasting.utils._utils.TupleOutputMixIn'>, <class 'object'>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43b535b5",
      "metadata": {
        "id": "43b535b5"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "1fad2cba",
      "metadata": {
        "id": "1fad2cba",
        "outputId": "b7342a98-4fa9-4f49-a60e-62157a89b606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting model evaluation...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'predict'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-43-2251884301.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Make predictions on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Calculate metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'predict'"
          ]
        }
      ],
      "source": [
        "with mlflow.start_run(run_name=\"TFT_Model_Evaluation\"):\n",
        "    print(\"Starting model evaluation...\")\n",
        "\n",
        "    # Make predictions on validation set\n",
        "    predictions = best_model.predict(val_dataloader, return_y=True)\n",
        "\n",
        "    # Calculate metrics\n",
        "    mae = MAE()(predictions.output, predictions.y).item()\n",
        "    smape = SMAPE()(predictions.output, predictions.y).item()\n",
        "    rmse = RMSE()(predictions.output, predictions.y).item()\n",
        "\n",
        "    # Log evaluation metrics\n",
        "    mlflow.log_metric(\"val_mae\", mae)\n",
        "    mlflow.log_metric(\"val_smape\", smape)\n",
        "    mlflow.log_metric(\"val_rmse\", rmse)\n",
        "\n",
        "    print(f\"Validation MAE: {mae:.4f}\")\n",
        "    print(f\"Validation SMAPE: {smape:.4f}\")\n",
        "    print(f\"Validation RMSE: {rmse:.4f}\")\n",
        "\n",
        "    # Create prediction plots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # Plot 1: Actual vs Predicted\n",
        "    actual = predictions.y.cpu().numpy().flatten()\n",
        "    predicted = predictions.output.cpu().numpy().flatten()\n",
        "\n",
        "    axes[0, 0].scatter(actual, predicted, alpha=0.5)\n",
        "    axes[0, 0].plot([actual.min(), actual.max()], [actual.min(), actual.max()], 'r--', lw=2)\n",
        "    axes[0, 0].set_xlabel('Actual')\n",
        "    axes[0, 0].set_ylabel('Predicted')\n",
        "    axes[0, 0].set_title('Actual vs Predicted')\n",
        "\n",
        "    # Plot 2: Residuals\n",
        "    residuals = actual - predicted\n",
        "    axes[0, 1].scatter(predicted, residuals, alpha=0.5)\n",
        "    axes[0, 1].axhline(y=0, color='r', linestyle='--')\n",
        "    axes[0, 1].set_xlabel('Predicted')\n",
        "    axes[0, 1].set_ylabel('Residuals')\n",
        "    axes[0, 1].set_title('Residual Plot')\n",
        "\n",
        "    # Plot 3: Residuals histogram\n",
        "    axes[1, 0].hist(residuals, bins=50, alpha=0.7)\n",
        "    axes[1, 0].set_xlabel('Residuals')\n",
        "    axes[1, 0].set_ylabel('Frequency')\n",
        "    axes[1, 0].set_title('Residuals Distribution')\n",
        "\n",
        "    # Plot 4: Time series example\n",
        "    example_idx = 0\n",
        "    example_prediction = predictions.output[example_idx].cpu().numpy()\n",
        "    example_actual = predictions.y[example_idx].cpu().numpy()\n",
        "\n",
        "    axes[1, 1].plot(range(len(example_actual)), example_actual, 'b-', label='Actual', linewidth=2)\n",
        "    axes[1, 1].plot(range(len(example_prediction)), example_prediction, 'r--', label='Predicted', linewidth=2)\n",
        "    axes[1, 1].set_xlabel('Time Steps')\n",
        "    axes[1, 1].set_ylabel('Weekly Sales')\n",
        "    axes[1, 1].set_title('Example Prediction')\n",
        "    axes[1, 1].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('tft_evaluation_plots.png', dpi=300, bbox_inches='tight')\n",
        "    mlflow.log_artifact('tft_evaluation_plots.png')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Model evaluation completed!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch-lightning==1.9.5 pytorch-forecasting==1.0.0\n"
      ],
      "metadata": {
        "id": "k1g9I7rYYOxM",
        "outputId": "1a1b12d0-1490-4484-b986-90fb5ff5c3b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "k1g9I7rYYOxM",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lightning==1.9.5\n",
            "  Using cached pytorch_lightning-1.9.5-py3-none-any.whl.metadata (23 kB)\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 0.10.2 Requires-Python >=3.8,<3.11; 0.10.3 Requires-Python >=3.8,<3.11; 1.0.0 Requires-Python >=3.8,<3.11\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement pytorch-forecasting==1.0.0 (from versions: 0.1.0, 0.1.1, 0.1.2, 0.2.0, 0.2.1, 0.2.2, 0.2.3, 0.2.4, 0.3.0, 0.3.1, 0.4.0, 0.4.1, 0.5.0, 0.5.1, 0.5.2, 0.5.3, 0.6.0, 0.6.1, 0.7.0, 0.7.1, 0.8.0, 0.8.1, 0.8.2, 0.8.3, 0.8.4, 0.8.5, 0.9.0, 0.9.1, 0.9.2, 0.10.0, 0.10.1, 1.1.0, 1.1.1, 1.2.0, 1.3.0, 1.4.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pytorch-forecasting==1.0.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2b58316",
      "metadata": {
        "id": "d2b58316"
      },
      "outputs": [],
      "source": [
        "# Hyperparameter Tuning (Optional)\n",
        "with mlflow.start_run(run_name=\"TFT_Hyperparameter_Tuning\"):\n",
        "    print(\"Starting hyperparameter tuning...\")\n",
        "\n",
        "    # Define hyperparameter ranges\n",
        "    study = optimize_hyperparameters(\n",
        "        train_dataloader,\n",
        "        val_dataloader,\n",
        "        model_path=\"optuna_test\",\n",
        "        n_trials=10,  # Reduce for faster execution\n",
        "        max_epochs=20,\n",
        "        gradient_clip_val_range=(0.01, 1.0),\n",
        "        hidden_size_range=(32, 128),\n",
        "        lstm_layers_range=(1, 4),\n",
        "        dropout_range=(0.1, 0.3),\n",
        "        attention_head_size_range=(1, 8),\n",
        "        learning_rate_range=(0.001, 0.1),\n",
        "        use_learning_rate_finder=False,\n",
        "    )\n",
        "\n",
        "    # Log best parameters\n",
        "    best_params = study.best_params\n",
        "    for key, value in best_params.items():\n",
        "        mlflow.log_param(f\"best_{key}\", value)\n",
        "\n",
        "    mlflow.log_metric(\"best_trial_value\", study.best_value)\n",
        "\n",
        "    print(f\"Best trial value: {study.best_value}\")\n",
        "    print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "# Final Model Training with Best Parameters\n",
        "with mlflow.start_run(run_name=\"TFT_Final_Model_Training\"):\n",
        "    print(\"Training final model with best parameters...\")\n",
        "\n",
        "    # Create final model with best parameters (use default if tuning was skipped)\n",
        "    final_tft = TemporalFusionTransformer.from_dataset(\n",
        "        training_dataset,\n",
        "        hidden_size=64,  # Use best params if available\n",
        "        lstm_layers=2,\n",
        "        dropout=0.1,\n",
        "        attention_head_size=4,\n",
        "        output_size=7,\n",
        "        loss=SMAPE(),\n",
        "        learning_rate=0.001,\n",
        "        reduce_on_plateau_patience=3,\n",
        "        optimizer=\"Adam\",\n",
        "    )\n",
        "\n",
        "    # Create final trainer\n",
        "    final_trainer = pl.Trainer(\n",
        "        max_epochs=100,\n",
        "        accelerator='cpu',\n",
        "        callbacks=[early_stopping, checkpoint_callback],\n",
        "        logger=mlflow_logger,\n",
        "        enable_progress_bar=True,\n",
        "        deterministic=True\n",
        "    )\n",
        "\n",
        "    # Train final model\n",
        "    final_trainer.fit(\n",
        "        final_tft,\n",
        "        train_dataloaders=train_dataloader,\n",
        "        val_dataloaders=val_dataloader\n",
        "    )\n",
        "\n",
        "    # Load best final model\n",
        "    final_best_model = TemporalFusionTransformer.load_from_checkpoint(\n",
        "        checkpoint_callback.best_model_path\n",
        "    )\n",
        "\n",
        "    print(\"Final model training completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e689e65",
      "metadata": {
        "id": "2e689e65"
      },
      "source": [
        "# Create Pipeline and Save Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c7a95e7",
      "metadata": {
        "id": "9c7a95e7"
      },
      "outputs": [],
      "source": [
        "with mlflow.start_run(run_name=\"TFT_Pipeline_Creation\"):\n",
        "    print(\"Creating TFT pipeline...\")\n",
        "\n",
        "    # Create a pipeline class for TFT\n",
        "    class TFTPipeline:\n",
        "        def __init__(self, model, dataset_config, preprocessing_params):\n",
        "            self.model = model\n",
        "            self.dataset_config = dataset_config\n",
        "            self.preprocessing_params = preprocessing_params\n",
        "            self.label_encoders = {}\n",
        "\n",
        "        def preprocess(self, data):\n",
        "            \"\"\"Preprocess raw data for TFT\"\"\"\n",
        "            # Apply the same preprocessing as training\n",
        "            data = data.copy()\n",
        "\n",
        "            # Convert Date to datetime\n",
        "            data['Date'] = pd.to_datetime(data['Date'])\n",
        "\n",
        "            # Engineer features\n",
        "            data['Year'] = data['Date'].dt.year\n",
        "            data['Month'] = data['Date'].dt.month\n",
        "            data['Week'] = data['Date'].dt.week\n",
        "            data['Day'] = data['Date'].dt.day\n",
        "            data['DayOfWeek'] = data['Date'].dt.dayofweek\n",
        "            data['Quarter'] = data['Date'].dt.quarter\n",
        "            data['IsHoliday'] = data['IsHoliday'].astype(int)\n",
        "\n",
        "            # Create time index\n",
        "            data['time_idx'] = (data['Date'] - self.preprocessing_params['min_date']).dt.days\n",
        "\n",
        "            # Handle categorical encoding\n",
        "            if 'Type' in data.columns:\n",
        "                data['Type_encoded'] = le_type.transform(data['Type'])\n",
        "\n",
        "            # Fill missing values\n",
        "            numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
        "            data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].median())\n",
        "\n",
        "            return data\n",
        "\n",
        "        def predict(self, data):\n",
        "            \"\"\"Make predictions on new data\"\"\"\n",
        "            # Preprocess data\n",
        "            processed_data = self.preprocess(data)\n",
        "\n",
        "            # Create dataset for prediction\n",
        "            prediction_dataset = TimeSeriesDataSet.from_dataset(\n",
        "                self.dataset_config,\n",
        "                processed_data,\n",
        "                predict=True,\n",
        "                stop_randomization=True\n",
        "            )\n",
        "\n",
        "            # Create dataloader\n",
        "            prediction_dataloader = prediction_dataset.to_dataloader(\n",
        "                train=False,\n",
        "                batch_size=128,\n",
        "                num_workers=0\n",
        "            )\n",
        "\n",
        "            # Make predictions\n",
        "            predictions = self.model.predict(prediction_dataloader)\n",
        "\n",
        "            return predictions\n",
        "\n",
        "    # Create pipeline\n",
        "    preprocessing_params = {\n",
        "        'min_date': train_df['Date'].min(),\n",
        "        'max_date': train_df['Date'].max(),\n",
        "        'features': list(train_df.columns)\n",
        "    }\n",
        "\n",
        "    tft_pipeline = TFTPipeline(\n",
        "        model=final_best_model,\n",
        "        dataset_config=training_dataset,\n",
        "        preprocessing_params=preprocessing_params\n",
        "    )\n",
        "\n",
        "    # Save pipeline\n",
        "    pipeline_path = \"tft_pipeline.pkl\"\n",
        "    joblib.dump(tft_pipeline, pipeline_path)\n",
        "\n",
        "    # Log pipeline\n",
        "    mlflow.log_artifact(pipeline_path)\n",
        "\n",
        "    # Save additional components\n",
        "    joblib.dump(le_type, \"label_encoder_type.pkl\")\n",
        "    mlflow.log_artifact(\"label_encoder_type.pkl\")\n",
        "\n",
        "    print(\"Pipeline creation completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b707dc3a",
      "metadata": {
        "id": "b707dc3a"
      },
      "source": [
        "# Model Registration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6ae809c",
      "metadata": {
        "id": "c6ae809c"
      },
      "outputs": [],
      "source": [
        "with mlflow.start_run(run_name=\"TFT_Model_Registration\"):\n",
        "    print(\"Registering model...\")\n",
        "\n",
        "    # Create model signature\n",
        "    sample_input = train_df.head(100)\n",
        "    sample_output = np.random.randn(100, max_prediction_length)\n",
        "    signature = infer_signature(sample_input, sample_output)\n",
        "\n",
        "    # Register model\n",
        "    model_name = \"TFT_Walmart_Sales_Forecast\"\n",
        "\n",
        "    mlflow.sklearn.log_model(\n",
        "        sk_model=tft_pipeline,\n",
        "        artifact_path=\"tft_model\",\n",
        "        signature=signature,\n",
        "        registered_model_name=model_name\n",
        "    )\n",
        "\n",
        "    print(f\"Model registered as '{model_name}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3c0a3dc",
      "metadata": {
        "id": "b3c0a3dc"
      },
      "outputs": [],
      "source": [
        "print(\"TFT experiment completed successfully!\")\n",
        "print(\"All artifacts and models have been logged to MLflow\")\n",
        "print(\"Check your MLflow UI to view the experiments and model registry\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "47ef9c4b680a4d59a31c2aa1fc471c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5bb1858e6a9745d8acf9da6b7e80a294",
              "IPY_MODEL_c5552a40448a4dd38e7af239c5bf7bb7",
              "IPY_MODEL_fcdbfcac322048999d6d3473475ce099"
            ],
            "layout": "IPY_MODEL_2515e0b01c7e40c482af3f3a5c74776b"
          }
        },
        "5bb1858e6a9745d8acf9da6b7e80a294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_930ba19096ec4a94a265f60c23e50b4e",
            "placeholder": "​",
            "style": "IPY_MODEL_ceb3c4965bba4c70bb4cd503a8ee5783",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "c5552a40448a4dd38e7af239c5bf7bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2708ffabf1f646f1a0d7ea2b6b2b7b92",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68cfe7fd89984847b62996603b903427",
            "value": 1
          }
        },
        "fcdbfcac322048999d6d3473475ce099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbb0564f1ac6440d91cea6791f0412a9",
            "placeholder": "​",
            "style": "IPY_MODEL_48fc91d26d1342b3ae329af1c0f5de0a",
            "value": " 1/1 [00:00&lt;00:00,  3.07it/s]"
          }
        },
        "2515e0b01c7e40c482af3f3a5c74776b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "930ba19096ec4a94a265f60c23e50b4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceb3c4965bba4c70bb4cd503a8ee5783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2708ffabf1f646f1a0d7ea2b6b2b7b92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68cfe7fd89984847b62996603b903427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fbb0564f1ac6440d91cea6791f0412a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48fc91d26d1342b3ae329af1c0f5de0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b253803b7665473db6c82aa588b812ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9865654d818e4d0c9ced1cba9d35f5ac",
              "IPY_MODEL_f3b5546c65004f3eb29b8ebf809c66a5",
              "IPY_MODEL_d4623f9b992442bc81874937486c5600"
            ],
            "layout": "IPY_MODEL_26c06d1545c6437e8bb0c6bb2301457a"
          }
        },
        "9865654d818e4d0c9ced1cba9d35f5ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_249ac93b637c49ecbde3a9ad1504a116",
            "placeholder": "​",
            "style": "IPY_MODEL_7e996875396249b4b33948428c9cab2c",
            "value": "Epoch 0:   0%"
          }
        },
        "f3b5546c65004f3eb29b8ebf809c66a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f89cde0ab88645d4b434e8a06b8dfdbc",
            "max": 6239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94e784dfb9cc42769e6fd1e9782c4349",
            "value": 0
          }
        },
        "d4623f9b992442bc81874937486c5600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2fdae4d3ee6443a85b68d46772f6692",
            "placeholder": "​",
            "style": "IPY_MODEL_6b14a3a86b264e3c86696559f0e70fd3",
            "value": " 0/6239 [00:00&lt;?, ?it/s]"
          }
        },
        "26c06d1545c6437e8bb0c6bb2301457a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "249ac93b637c49ecbde3a9ad1504a116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e996875396249b4b33948428c9cab2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f89cde0ab88645d4b434e8a06b8dfdbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94e784dfb9cc42769e6fd1e9782c4349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2fdae4d3ee6443a85b68d46772f6692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b14a3a86b264e3c86696559f0e70fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}